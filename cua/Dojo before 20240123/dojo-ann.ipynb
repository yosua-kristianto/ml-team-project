{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow;\n",
    "import pandas;\n",
    "from sklearn.model_selection import train_test_split;\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt;\n",
    "from tensorflow.keras.utils import plot_model;\n",
    "import requests;\n",
    "import time;\n",
    "\n",
    "from imblearn.over_sampling import SMOTE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0      20000    2          2         1   24      2      2     -1     -1   \n",
       "1     120000    2          2         2   26     -1      2      0      0   \n",
       "2      90000    2          2         2   34      0      0      0      0   \n",
       "3      50000    2          2         1   37      0      0      0      0   \n",
       "4      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0     -2  ...          0          0          0         0       689         0   \n",
       "1      0  ...       3272       3455       3261         0      1000      1000   \n",
       "2      0  ...      14331      14948      15549      1518      1500      1000   \n",
       "3      0  ...      28314      28959      29547      2000      2019      1200   \n",
       "4      0  ...      20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  LABEL  \n",
       "0         0         0         0      1  \n",
       "1      1000         0      2000      1  \n",
       "2      1000      1000      5000      0  \n",
       "3      1100      1069      1000      0  \n",
       "4      9000       689       679      0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data from pre-cleaned csv file\n",
    "current_folder = \"/mnt/d/Code/College/Machine Learning/Team Assignment/Default Credit Scoring/\";\n",
    "# current_folder = \"\";\n",
    "dataframe = pandas.read_csv(current_folder + \"credit_card_clients.csv\");\n",
    "\n",
    "dataframe = dataframe.drop(columns = [\"ID\"]);\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Correlation\n",
    "\n",
    "In this section I set the treshold with 0.2. Any feature below 0.2 will be discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship : Correlation Score\n",
      "LIMIT_BAL -> LABEL :  -0.1535198763935072\n",
      "Dropping  LIMIT_BAL\n",
      "SEX -> LABEL :  -0.03996057770544172\n",
      "Dropping  SEX\n",
      "EDUCATION -> LABEL :  0.028006077656250204\n",
      "MARRIAGE -> LABEL :  -0.024339215683404438\n",
      "Dropping  MARRIAGE\n",
      "AGE -> LABEL :  0.013889834301962887\n",
      "PAY_0 -> LABEL :  0.32479372847862237\n",
      "PAY_2 -> LABEL :  0.2635512016721678\n",
      "PAY_3 -> LABEL :  0.23525251372491712\n",
      "PAY_4 -> LABEL :  0.21661363684242388\n",
      "PAY_5 -> LABEL :  0.2041489138761645\n",
      "PAY_6 -> LABEL :  0.18686636165354611\n",
      "BILL_AMT1 -> LABEL :  -0.019644197143221562\n",
      "Dropping  BILL_AMT1\n",
      "BILL_AMT2 -> LABEL :  -0.014193218088215756\n",
      "Dropping  BILL_AMT2\n",
      "BILL_AMT3 -> LABEL :  -0.014075518043214726\n",
      "Dropping  BILL_AMT3\n",
      "BILL_AMT4 -> LABEL :  -0.010156495880289674\n",
      "Dropping  BILL_AMT4\n",
      "BILL_AMT5 -> LABEL :  -0.006760463841014779\n",
      "Dropping  BILL_AMT5\n",
      "BILL_AMT6 -> LABEL :  -0.005372314914815558\n",
      "Dropping  BILL_AMT6\n",
      "PAY_AMT1 -> LABEL :  -0.07292948777785163\n",
      "Dropping  PAY_AMT1\n",
      "PAY_AMT2 -> LABEL :  -0.058578706582901575\n",
      "Dropping  PAY_AMT2\n",
      "PAY_AMT3 -> LABEL :  -0.056250350990331634\n",
      "Dropping  PAY_AMT3\n",
      "PAY_AMT4 -> LABEL :  -0.05682740089288691\n",
      "Dropping  PAY_AMT4\n",
      "PAY_AMT5 -> LABEL :  -0.05512351562108876\n",
      "Dropping  PAY_AMT5\n",
      "PAY_AMT6 -> LABEL :  -0.05318334032612796\n",
      "Dropping  PAY_AMT6\n",
      "LABEL -> LABEL :  1.0\n"
     ]
    }
   ],
   "source": [
    "# Correlation Heatmap\n",
    "correlation = dataframe.corr();\n",
    "\n",
    "TRESHOLD = 0;\n",
    "print(\"Relationship : Correlation Score\");\n",
    "\n",
    "columns_to_be_dropped = [];\n",
    "for i in correlation.columns:\n",
    "    correlation_score = correlation[i][\"LABEL\"];\n",
    "    print(i, \"-> LABEL : \", correlation_score);\n",
    "\n",
    "    # When data are oversampled, Education seems more uncorrelated through the LABEL. Skipping drop the Education.\n",
    "    if(i == \"EDUCATION\"):\n",
    "        continue;\n",
    "\n",
    "    if(correlation_score < TRESHOLD):\n",
    "        columns_to_be_dropped.append(i);\n",
    "        print(\"Dropping \", i);\n",
    "\n",
    "dataframe = dataframe.drop(columns=columns_to_be_dropped);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "Checkout the `main.ipynb` since I just copy-pasting the whole thing from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after cleaning:  (29655, 77)\n",
      "['EDUCATION', 'AGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'LABEL', 'education_1', 'education_2', 'education_3', 'education_4', 'pay_0_-2', 'pay_0_-1', 'pay_0_0', 'pay_0_1', 'pay_0_2', 'pay_0_3', 'pay_0_4', 'pay_0_5', 'pay_0_6', 'pay_0_7', 'pay_0_8', 'pay_2_-2', 'pay_2_-1', 'pay_2_0', 'pay_2_1', 'pay_2_2', 'pay_2_3', 'pay_2_4', 'pay_2_5', 'pay_2_6', 'pay_2_7', 'pay_2_8', 'pay_3_-2', 'pay_3_-1', 'pay_3_0', 'pay_3_1', 'pay_3_2', 'pay_3_3', 'pay_3_4', 'pay_3_5', 'pay_3_6', 'pay_3_7', 'pay_3_8', 'pay_4_-2', 'pay_4_-1', 'pay_4_0', 'pay_4_1', 'pay_4_2', 'pay_4_3', 'pay_4_4', 'pay_4_5', 'pay_4_6', 'pay_4_7', 'pay_4_8', 'pay_5_-2', 'pay_5_-1', 'pay_5_0', 'pay_5_2', 'pay_5_3', 'pay_5_4', 'pay_5_5', 'pay_5_6', 'pay_5_7', 'pay_5_8', 'pay_6_-2', 'pay_6_-1', 'pay_6_0', 'pay_6_2', 'pay_6_3', 'pay_6_4', 'pay_6_5', 'pay_6_6', 'pay_6_7', 'pay_6_8']\n"
     ]
    }
   ],
   "source": [
    "# Some education data contains 0, 5, and 6. I eliminating \"em.\n",
    "\n",
    "invalid_education_data = [];\n",
    "for idx, e in enumerate(dataframe['EDUCATION']):\n",
    "    if(e > 4 or e < 1):\n",
    "        invalid_education_data.append(idx);\n",
    "\n",
    "dataframe = dataframe.drop(invalid_education_data);\n",
    "\n",
    "# Make one hot encoding for Educuation and PAY_0 to 6 since the data is an ordinal data\n",
    "hot_encoded_education = pandas.get_dummies(dataframe['EDUCATION'], prefix = \"education\");\n",
    "hot_encoded_pay_0 = pandas.get_dummies(dataframe['PAY_0'], prefix = \"pay_0\");\n",
    "hot_encoded_pay_2 = pandas.get_dummies(dataframe['PAY_2'], prefix = \"pay_2\");\n",
    "hot_encoded_pay_3 = pandas.get_dummies(dataframe['PAY_3'], prefix = \"pay_3\");\n",
    "hot_encoded_pay_4 = pandas.get_dummies(dataframe['PAY_4'], prefix = \"pay_4\");\n",
    "hot_encoded_pay_5 = pandas.get_dummies(dataframe['PAY_5'], prefix = \"pay_5\");\n",
    "hot_encoded_pay_6 = pandas.get_dummies(dataframe['PAY_6'], prefix = \"pay_6\");\n",
    "\n",
    "# Merge the hot_encoded with the main dataframe\n",
    "for i in [hot_encoded_education, hot_encoded_pay_0, hot_encoded_pay_2, hot_encoded_pay_3, hot_encoded_pay_4, hot_encoded_pay_5, hot_encoded_pay_6]:\n",
    "    dataframe = pandas.concat([dataframe, i], axis = 1);\n",
    "\n",
    "print(\"Data after cleaning: \", dataframe.shape);\n",
    "print(dataframe.columns.tolist());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define label data\n",
    "label = dataframe['LABEL'];\n",
    "\n",
    "# Drop ID, SEX, EDUCATION, MARRIAGE, and LABEL from dataframe for features\n",
    "features = dataframe.drop(columns=[\"EDUCATION\", 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', \"LABEL\"]);\n",
    "\n",
    "# Typecasting all values within to int64 because ANN need to be standardized\n",
    "\n",
    "for i in dataframe.columns:\n",
    "    dataframe[i] = dataframe[i].astype(int);\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "feature_train, feature_test, label_train, label_test = train_test_split(features, label, train_size = 0.7, test_size = 0.3, random_state = 42);\n",
    "feature_validation, feature_test, label_validation, label_test = train_test_split(feature_test, label_test, test_size=0.5, random_state = 42);\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler();\n",
    "feature_train_scaled = scaler.fit_transform(feature_train);\n",
    "feature_validation_scaled = scaler.fit_transform(feature_validation);\n",
    "feature_test_scaled = scaler.transform(feature_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def telegram_reporter(message):\n",
    "    message = \"[\"+ time.strftime(\"%Y-%m-%d %H:%M:%S\") +\"] \" + message\n",
    "    requests.request(method=\"POST\", url=\"https://api.telegram.org/bot6307342709:AAEehfQrvZzQhk2hFlOW7C1JnE2hRQYLEgE/sendMessage?chat_id=-1001525528850&text=\" + message, headers={}, data={});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tunning\n",
    "\n",
    "This code based on Tensorflow Artifical Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256)\n",
      "(None, 256)\n",
      "(None, 256)\n",
      "(None, 256)\n",
      "(None, 256)\n",
      "(None, 256)\n",
      "(None, 256)\n",
      "(None, 256)\n",
      "(None, 128)\n",
      "(None, 128)\n",
      "(None, 128)\n",
      "(None, 64)\n",
      "(None, 64)\n",
      "(None, 64)\n",
      "(None, 64)\n",
      "(None, 64)\n",
      "(None, 64)\n",
      "(None, 64)\n",
      "(None, 64)\n",
      "(None, 32)\n",
      "(None, 32)\n",
      "(None, 32)\n",
      "(None, 32)\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_85 (Dense)            (None, 256)               17920     \n",
      "                                                                 \n",
      " activation_27 (Activation)  (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_69 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " activation_28 (Activation)  (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_70 (Ba  (None, 256)               1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_71 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_88 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " activation_29 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " batch_normalization_72 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_89 (Dense)            (None, 64)                4160      \n",
      "                                                                 \n",
      " activation_30 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " batch_normalization_73 (Ba  (None, 64)                256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_90 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " activation_31 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " batch_normalization_74 (Ba  (None, 32)                128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_91 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134337 (524.75 KB)\n",
      "Trainable params: 132737 (518.50 KB)\n",
      "Non-trainable params: 1600 (6.25 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n",
      "649/649 [==============================] - 15s 17ms/step - loss: 0.6593 - accuracy: 0.7124 - val_loss: 0.5493 - val_accuracy: 0.7871\n",
      "Epoch 2/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.5568 - accuracy: 0.7893 - val_loss: 0.5296 - val_accuracy: 0.7981\n",
      "Epoch 3/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.5378 - accuracy: 0.7959 - val_loss: 0.5248 - val_accuracy: 0.7992\n",
      "Epoch 4/1000\n",
      "649/649 [==============================] - 10s 15ms/step - loss: 0.5298 - accuracy: 0.7992 - val_loss: 0.5235 - val_accuracy: 0.8006\n",
      "Epoch 5/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.5178 - accuracy: 0.8062 - val_loss: 0.5148 - val_accuracy: 0.8024\n",
      "Epoch 6/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.5092 - accuracy: 0.8078 - val_loss: 0.5045 - val_accuracy: 0.8053\n",
      "Epoch 7/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.5044 - accuracy: 0.8116 - val_loss: 0.4980 - val_accuracy: 0.8107\n",
      "Epoch 8/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4990 - accuracy: 0.8100 - val_loss: 0.4927 - val_accuracy: 0.8116\n",
      "Epoch 9/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4919 - accuracy: 0.8140 - val_loss: 0.4930 - val_accuracy: 0.8089\n",
      "Epoch 10/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4858 - accuracy: 0.8120 - val_loss: 0.4823 - val_accuracy: 0.8100\n",
      "Epoch 11/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4801 - accuracy: 0.8149 - val_loss: 0.4797 - val_accuracy: 0.8091\n",
      "Epoch 12/1000\n",
      "649/649 [==============================] - 10s 15ms/step - loss: 0.4788 - accuracy: 0.8134 - val_loss: 0.4793 - val_accuracy: 0.8105\n",
      "Epoch 13/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4765 - accuracy: 0.8139 - val_loss: 0.4750 - val_accuracy: 0.8087\n",
      "Epoch 14/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4733 - accuracy: 0.8138 - val_loss: 0.4749 - val_accuracy: 0.8080\n",
      "Epoch 15/1000\n",
      "649/649 [==============================] - 9s 15ms/step - loss: 0.4722 - accuracy: 0.8139 - val_loss: 0.4743 - val_accuracy: 0.8080\n",
      "Epoch 16/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4710 - accuracy: 0.8161 - val_loss: 0.4734 - val_accuracy: 0.8114\n",
      "Epoch 17/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4712 - accuracy: 0.8123 - val_loss: 0.4737 - val_accuracy: 0.8100\n",
      "Epoch 18/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4695 - accuracy: 0.8161 - val_loss: 0.4717 - val_accuracy: 0.8118\n",
      "Epoch 19/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4693 - accuracy: 0.8126 - val_loss: 0.4714 - val_accuracy: 0.8125\n",
      "Epoch 20/1000\n",
      "649/649 [==============================] - 10s 15ms/step - loss: 0.4703 - accuracy: 0.8156 - val_loss: 0.4723 - val_accuracy: 0.8089\n",
      "Epoch 21/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4696 - accuracy: 0.8161 - val_loss: 0.4692 - val_accuracy: 0.8123\n",
      "Epoch 22/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4684 - accuracy: 0.8157 - val_loss: 0.4690 - val_accuracy: 0.8123\n",
      "Epoch 23/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4679 - accuracy: 0.8158 - val_loss: 0.4705 - val_accuracy: 0.8098\n",
      "Epoch 24/1000\n",
      "649/649 [==============================] - 12s 18ms/step - loss: 0.4688 - accuracy: 0.8138 - val_loss: 0.4699 - val_accuracy: 0.8125\n",
      "Epoch 25/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4676 - accuracy: 0.8136 - val_loss: 0.4689 - val_accuracy: 0.8098\n",
      "Epoch 26/1000\n",
      "649/649 [==============================] - 13s 21ms/step - loss: 0.4662 - accuracy: 0.8148 - val_loss: 0.4690 - val_accuracy: 0.8087\n",
      "Epoch 27/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4673 - accuracy: 0.8141 - val_loss: 0.4694 - val_accuracy: 0.8114\n",
      "Epoch 28/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4667 - accuracy: 0.8137 - val_loss: 0.4683 - val_accuracy: 0.8123\n",
      "Epoch 29/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4671 - accuracy: 0.8150 - val_loss: 0.4677 - val_accuracy: 0.8127\n",
      "Epoch 30/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4666 - accuracy: 0.8126 - val_loss: 0.4696 - val_accuracy: 0.8103\n",
      "Epoch 31/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4665 - accuracy: 0.8149 - val_loss: 0.4724 - val_accuracy: 0.8112\n",
      "Epoch 32/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4673 - accuracy: 0.8154 - val_loss: 0.4700 - val_accuracy: 0.8116\n",
      "Epoch 33/1000\n",
      "649/649 [==============================] - 10s 15ms/step - loss: 0.4671 - accuracy: 0.8143 - val_loss: 0.4677 - val_accuracy: 0.8136\n",
      "Epoch 34/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4665 - accuracy: 0.8160 - val_loss: 0.4690 - val_accuracy: 0.8125\n",
      "Epoch 35/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4675 - accuracy: 0.8124 - val_loss: 0.4704 - val_accuracy: 0.8096\n",
      "Epoch 36/1000\n",
      "649/649 [==============================] - 10s 15ms/step - loss: 0.4666 - accuracy: 0.8126 - val_loss: 0.4664 - val_accuracy: 0.8121\n",
      "Epoch 37/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4655 - accuracy: 0.8154 - val_loss: 0.4675 - val_accuracy: 0.8129\n",
      "Epoch 38/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4657 - accuracy: 0.8131 - val_loss: 0.4686 - val_accuracy: 0.8103\n",
      "Epoch 39/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4669 - accuracy: 0.8142 - val_loss: 0.4693 - val_accuracy: 0.8129\n",
      "Epoch 40/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4667 - accuracy: 0.8150 - val_loss: 0.4669 - val_accuracy: 0.8107\n",
      "Epoch 41/1000\n",
      "649/649 [==============================] - 10s 15ms/step - loss: 0.4664 - accuracy: 0.8128 - val_loss: 0.4678 - val_accuracy: 0.8121\n",
      "Epoch 42/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4655 - accuracy: 0.8150 - val_loss: 0.4685 - val_accuracy: 0.8121\n",
      "Epoch 43/1000\n",
      "649/649 [==============================] - 10s 15ms/step - loss: 0.4642 - accuracy: 0.8172 - val_loss: 0.4664 - val_accuracy: 0.8114\n",
      "Epoch 44/1000\n",
      "649/649 [==============================] - 10s 15ms/step - loss: 0.4651 - accuracy: 0.8143 - val_loss: 0.4681 - val_accuracy: 0.8121\n",
      "Epoch 45/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4661 - accuracy: 0.8137 - val_loss: 0.4701 - val_accuracy: 0.8100\n",
      "Epoch 46/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4654 - accuracy: 0.8146 - val_loss: 0.4678 - val_accuracy: 0.8112\n",
      "Epoch 47/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4662 - accuracy: 0.8118 - val_loss: 0.4640 - val_accuracy: 0.8136\n",
      "Epoch 48/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4652 - accuracy: 0.8134 - val_loss: 0.4698 - val_accuracy: 0.8136\n",
      "Epoch 49/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4638 - accuracy: 0.8168 - val_loss: 0.4676 - val_accuracy: 0.8118\n",
      "Epoch 50/1000\n",
      "649/649 [==============================] - 10s 15ms/step - loss: 0.4647 - accuracy: 0.8135 - val_loss: 0.4704 - val_accuracy: 0.8094\n",
      "Epoch 51/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4643 - accuracy: 0.8160 - val_loss: 0.4675 - val_accuracy: 0.8107\n",
      "Epoch 52/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4643 - accuracy: 0.8139 - val_loss: 0.4672 - val_accuracy: 0.8112\n",
      "Epoch 53/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4642 - accuracy: 0.8167 - val_loss: 0.4655 - val_accuracy: 0.8107\n",
      "Epoch 54/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4664 - accuracy: 0.8130 - val_loss: 0.4676 - val_accuracy: 0.8118\n",
      "Epoch 55/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4637 - accuracy: 0.8155 - val_loss: 0.4680 - val_accuracy: 0.8123\n",
      "Epoch 56/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4644 - accuracy: 0.8138 - val_loss: 0.4635 - val_accuracy: 0.8123\n",
      "Epoch 57/1000\n",
      "649/649 [==============================] - 12s 18ms/step - loss: 0.4651 - accuracy: 0.8128 - val_loss: 0.4636 - val_accuracy: 0.8121\n",
      "Epoch 58/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4649 - accuracy: 0.8151 - val_loss: 0.4656 - val_accuracy: 0.8109\n",
      "Epoch 59/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4644 - accuracy: 0.8135 - val_loss: 0.4628 - val_accuracy: 0.8138\n",
      "Epoch 60/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4629 - accuracy: 0.8122 - val_loss: 0.4668 - val_accuracy: 0.8123\n",
      "Epoch 61/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4626 - accuracy: 0.8144 - val_loss: 0.4659 - val_accuracy: 0.8118\n",
      "Epoch 62/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4625 - accuracy: 0.8166 - val_loss: 0.4636 - val_accuracy: 0.8132\n",
      "Epoch 63/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4632 - accuracy: 0.8121 - val_loss: 0.4625 - val_accuracy: 0.8127\n",
      "Epoch 64/1000\n",
      "649/649 [==============================] - 10s 15ms/step - loss: 0.4628 - accuracy: 0.8136 - val_loss: 0.4639 - val_accuracy: 0.8109\n",
      "Epoch 65/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4628 - accuracy: 0.8138 - val_loss: 0.4632 - val_accuracy: 0.8118\n",
      "Epoch 66/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4648 - accuracy: 0.8135 - val_loss: 0.4660 - val_accuracy: 0.8121\n",
      "Epoch 67/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4617 - accuracy: 0.8140 - val_loss: 0.4658 - val_accuracy: 0.8125\n",
      "Epoch 68/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4641 - accuracy: 0.8127 - val_loss: 0.4644 - val_accuracy: 0.8121\n",
      "Epoch 69/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4647 - accuracy: 0.8141 - val_loss: 0.4649 - val_accuracy: 0.8127\n",
      "Epoch 70/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4622 - accuracy: 0.8175 - val_loss: 0.4643 - val_accuracy: 0.8105\n",
      "Epoch 71/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4629 - accuracy: 0.8147 - val_loss: 0.4618 - val_accuracy: 0.8118\n",
      "Epoch 72/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4638 - accuracy: 0.8129 - val_loss: 0.4627 - val_accuracy: 0.8116\n",
      "Epoch 73/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4631 - accuracy: 0.8143 - val_loss: 0.4619 - val_accuracy: 0.8123\n",
      "Epoch 74/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4636 - accuracy: 0.8146 - val_loss: 0.4638 - val_accuracy: 0.8114\n",
      "Epoch 75/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4635 - accuracy: 0.8138 - val_loss: 0.4644 - val_accuracy: 0.8096\n",
      "Epoch 76/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4636 - accuracy: 0.8156 - val_loss: 0.4619 - val_accuracy: 0.8112\n",
      "Epoch 77/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4634 - accuracy: 0.8126 - val_loss: 0.4617 - val_accuracy: 0.8121\n",
      "Epoch 78/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4636 - accuracy: 0.8138 - val_loss: 0.4632 - val_accuracy: 0.8112\n",
      "Epoch 79/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4607 - accuracy: 0.8162 - val_loss: 0.4614 - val_accuracy: 0.8125\n",
      "Epoch 80/1000\n",
      "649/649 [==============================] - 10s 15ms/step - loss: 0.4609 - accuracy: 0.8163 - val_loss: 0.4607 - val_accuracy: 0.8109\n",
      "Epoch 81/1000\n",
      "649/649 [==============================] - 10s 15ms/step - loss: 0.4612 - accuracy: 0.8158 - val_loss: 0.4648 - val_accuracy: 0.8116\n",
      "Epoch 82/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4636 - accuracy: 0.8135 - val_loss: 0.4629 - val_accuracy: 0.8125\n",
      "Epoch 83/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4605 - accuracy: 0.8140 - val_loss: 0.4671 - val_accuracy: 0.8107\n",
      "Epoch 84/1000\n",
      "649/649 [==============================] - 10s 15ms/step - loss: 0.4618 - accuracy: 0.8134 - val_loss: 0.4614 - val_accuracy: 0.8116\n",
      "Epoch 85/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4608 - accuracy: 0.8131 - val_loss: 0.4641 - val_accuracy: 0.8118\n",
      "Epoch 86/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4619 - accuracy: 0.8140 - val_loss: 0.4637 - val_accuracy: 0.8107\n",
      "Epoch 87/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4631 - accuracy: 0.8139 - val_loss: 0.4617 - val_accuracy: 0.8123\n",
      "Epoch 88/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4636 - accuracy: 0.8128 - val_loss: 0.4619 - val_accuracy: 0.8132\n",
      "Epoch 89/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4638 - accuracy: 0.8150 - val_loss: 0.4633 - val_accuracy: 0.8125\n",
      "Epoch 90/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4609 - accuracy: 0.8169 - val_loss: 0.4636 - val_accuracy: 0.8123\n",
      "Epoch 91/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4629 - accuracy: 0.8141 - val_loss: 0.4615 - val_accuracy: 0.8132\n",
      "Epoch 92/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4618 - accuracy: 0.8144 - val_loss: 0.4636 - val_accuracy: 0.8114\n",
      "Epoch 93/1000\n",
      "649/649 [==============================] - 10s 15ms/step - loss: 0.4614 - accuracy: 0.8147 - val_loss: 0.4613 - val_accuracy: 0.8123\n",
      "Epoch 94/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4592 - accuracy: 0.8167 - val_loss: 0.4621 - val_accuracy: 0.8121\n",
      "Epoch 95/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4616 - accuracy: 0.8141 - val_loss: 0.4611 - val_accuracy: 0.8121\n",
      "Epoch 96/1000\n",
      "649/649 [==============================] - 10s 15ms/step - loss: 0.4630 - accuracy: 0.8123 - val_loss: 0.4605 - val_accuracy: 0.8107\n",
      "Epoch 97/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4624 - accuracy: 0.8122 - val_loss: 0.4622 - val_accuracy: 0.8112\n",
      "Epoch 98/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4606 - accuracy: 0.8147 - val_loss: 0.4610 - val_accuracy: 0.8132\n",
      "Epoch 99/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4612 - accuracy: 0.8127 - val_loss: 0.4612 - val_accuracy: 0.8114\n",
      "Epoch 100/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4616 - accuracy: 0.8148 - val_loss: 0.4611 - val_accuracy: 0.8118\n",
      "Epoch 101/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4611 - accuracy: 0.8131 - val_loss: 0.4618 - val_accuracy: 0.8121\n",
      "Epoch 102/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4626 - accuracy: 0.8141 - val_loss: 0.4631 - val_accuracy: 0.8123\n",
      "Epoch 103/1000\n",
      "649/649 [==============================] - 12s 18ms/step - loss: 0.4614 - accuracy: 0.8143 - val_loss: 0.4617 - val_accuracy: 0.8123\n",
      "Epoch 104/1000\n",
      "649/649 [==============================] - 12s 19ms/step - loss: 0.4623 - accuracy: 0.8124 - val_loss: 0.4605 - val_accuracy: 0.8114\n",
      "Epoch 105/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4619 - accuracy: 0.8125 - val_loss: 0.4599 - val_accuracy: 0.8109\n",
      "Epoch 106/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4607 - accuracy: 0.8138 - val_loss: 0.4622 - val_accuracy: 0.8134\n",
      "Epoch 107/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4619 - accuracy: 0.8125 - val_loss: 0.4614 - val_accuracy: 0.8112\n",
      "Epoch 108/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4625 - accuracy: 0.8145 - val_loss: 0.4664 - val_accuracy: 0.8118\n",
      "Epoch 109/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4611 - accuracy: 0.8147 - val_loss: 0.4623 - val_accuracy: 0.8109\n",
      "Epoch 110/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4636 - accuracy: 0.8118 - val_loss: 0.4614 - val_accuracy: 0.8121\n",
      "Epoch 111/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4600 - accuracy: 0.8161 - val_loss: 0.4601 - val_accuracy: 0.8105\n",
      "Epoch 112/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4610 - accuracy: 0.8161 - val_loss: 0.4619 - val_accuracy: 0.8125\n",
      "Epoch 113/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4590 - accuracy: 0.8168 - val_loss: 0.4639 - val_accuracy: 0.8123\n",
      "Epoch 114/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4620 - accuracy: 0.8149 - val_loss: 0.4614 - val_accuracy: 0.8116\n",
      "Epoch 115/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4625 - accuracy: 0.8129 - val_loss: 0.4612 - val_accuracy: 0.8121\n",
      "Epoch 116/1000\n",
      "649/649 [==============================] - 12s 18ms/step - loss: 0.4597 - accuracy: 0.8147 - val_loss: 0.4630 - val_accuracy: 0.8107\n",
      "Epoch 117/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4603 - accuracy: 0.8148 - val_loss: 0.4599 - val_accuracy: 0.8094\n",
      "Epoch 118/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4607 - accuracy: 0.8135 - val_loss: 0.4631 - val_accuracy: 0.8116\n",
      "Epoch 119/1000\n",
      "649/649 [==============================] - 12s 19ms/step - loss: 0.4607 - accuracy: 0.8133 - val_loss: 0.4596 - val_accuracy: 0.8123\n",
      "Epoch 120/1000\n",
      "649/649 [==============================] - 13s 20ms/step - loss: 0.4598 - accuracy: 0.8165 - val_loss: 0.4591 - val_accuracy: 0.8121\n",
      "Epoch 121/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4630 - accuracy: 0.8136 - val_loss: 0.4621 - val_accuracy: 0.8123\n",
      "Epoch 122/1000\n",
      "649/649 [==============================] - 12s 18ms/step - loss: 0.4608 - accuracy: 0.8136 - val_loss: 0.4596 - val_accuracy: 0.8109\n",
      "Epoch 123/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4614 - accuracy: 0.8134 - val_loss: 0.4653 - val_accuracy: 0.8096\n",
      "Epoch 124/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4605 - accuracy: 0.8140 - val_loss: 0.4622 - val_accuracy: 0.8132\n",
      "Epoch 125/1000\n",
      "649/649 [==============================] - 11s 18ms/step - loss: 0.4617 - accuracy: 0.8128 - val_loss: 0.4592 - val_accuracy: 0.8127\n",
      "Epoch 126/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4607 - accuracy: 0.8146 - val_loss: 0.4602 - val_accuracy: 0.8127\n",
      "Epoch 127/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4614 - accuracy: 0.8144 - val_loss: 0.4639 - val_accuracy: 0.8103\n",
      "Epoch 128/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4595 - accuracy: 0.8143 - val_loss: 0.4598 - val_accuracy: 0.8116\n",
      "Epoch 129/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4600 - accuracy: 0.8142 - val_loss: 0.4602 - val_accuracy: 0.8112\n",
      "Epoch 130/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4595 - accuracy: 0.8153 - val_loss: 0.4599 - val_accuracy: 0.8114\n",
      "Epoch 131/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4589 - accuracy: 0.8150 - val_loss: 0.4623 - val_accuracy: 0.8123\n",
      "Epoch 132/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4615 - accuracy: 0.8141 - val_loss: 0.4607 - val_accuracy: 0.8123\n",
      "Epoch 133/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4592 - accuracy: 0.8140 - val_loss: 0.4593 - val_accuracy: 0.8114\n",
      "Epoch 134/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4594 - accuracy: 0.8144 - val_loss: 0.4598 - val_accuracy: 0.8118\n",
      "Epoch 135/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4596 - accuracy: 0.8150 - val_loss: 0.4610 - val_accuracy: 0.8121\n",
      "Epoch 136/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4599 - accuracy: 0.8159 - val_loss: 0.4617 - val_accuracy: 0.8136\n",
      "Epoch 137/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4600 - accuracy: 0.8148 - val_loss: 0.4603 - val_accuracy: 0.8129\n",
      "Epoch 138/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4615 - accuracy: 0.8125 - val_loss: 0.4589 - val_accuracy: 0.8132\n",
      "Epoch 139/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4604 - accuracy: 0.8145 - val_loss: 0.4600 - val_accuracy: 0.8125\n",
      "Epoch 140/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4592 - accuracy: 0.8164 - val_loss: 0.4596 - val_accuracy: 0.8136\n",
      "Epoch 141/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4595 - accuracy: 0.8144 - val_loss: 0.4591 - val_accuracy: 0.8116\n",
      "Epoch 142/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4599 - accuracy: 0.8136 - val_loss: 0.4604 - val_accuracy: 0.8109\n",
      "Epoch 143/1000\n",
      "649/649 [==============================] - 12s 18ms/step - loss: 0.4601 - accuracy: 0.8139 - val_loss: 0.4592 - val_accuracy: 0.8132\n",
      "Epoch 144/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4608 - accuracy: 0.8132 - val_loss: 0.4649 - val_accuracy: 0.8118\n",
      "Epoch 145/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4603 - accuracy: 0.8143 - val_loss: 0.4606 - val_accuracy: 0.8121\n",
      "Epoch 146/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4585 - accuracy: 0.8144 - val_loss: 0.4583 - val_accuracy: 0.8123\n",
      "Epoch 147/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4599 - accuracy: 0.8174 - val_loss: 0.4615 - val_accuracy: 0.8129\n",
      "Epoch 148/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4601 - accuracy: 0.8140 - val_loss: 0.4589 - val_accuracy: 0.8118\n",
      "Epoch 149/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4610 - accuracy: 0.8144 - val_loss: 0.4587 - val_accuracy: 0.8138\n",
      "Epoch 150/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4602 - accuracy: 0.8162 - val_loss: 0.4603 - val_accuracy: 0.8121\n",
      "Epoch 151/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4582 - accuracy: 0.8166 - val_loss: 0.4593 - val_accuracy: 0.8116\n",
      "Epoch 152/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4594 - accuracy: 0.8150 - val_loss: 0.4635 - val_accuracy: 0.8116\n",
      "Epoch 153/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4605 - accuracy: 0.8143 - val_loss: 0.4601 - val_accuracy: 0.8136\n",
      "Epoch 154/1000\n",
      "649/649 [==============================] - 11s 18ms/step - loss: 0.4607 - accuracy: 0.8153 - val_loss: 0.4622 - val_accuracy: 0.8116\n",
      "Epoch 155/1000\n",
      "649/649 [==============================] - 11s 18ms/step - loss: 0.4610 - accuracy: 0.8156 - val_loss: 0.4582 - val_accuracy: 0.8125\n",
      "Epoch 156/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4601 - accuracy: 0.8158 - val_loss: 0.4609 - val_accuracy: 0.8121\n",
      "Epoch 157/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4604 - accuracy: 0.8148 - val_loss: 0.4589 - val_accuracy: 0.8127\n",
      "Epoch 158/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4602 - accuracy: 0.8157 - val_loss: 0.4597 - val_accuracy: 0.8125\n",
      "Epoch 159/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4598 - accuracy: 0.8156 - val_loss: 0.4597 - val_accuracy: 0.8125\n",
      "Epoch 160/1000\n",
      "649/649 [==============================] - 12s 18ms/step - loss: 0.4592 - accuracy: 0.8126 - val_loss: 0.4574 - val_accuracy: 0.8138\n",
      "Epoch 161/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4582 - accuracy: 0.8143 - val_loss: 0.4592 - val_accuracy: 0.8127\n",
      "Epoch 162/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4617 - accuracy: 0.8132 - val_loss: 0.4586 - val_accuracy: 0.8118\n",
      "Epoch 163/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4584 - accuracy: 0.8147 - val_loss: 0.4601 - val_accuracy: 0.8125\n",
      "Epoch 164/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4612 - accuracy: 0.8130 - val_loss: 0.4670 - val_accuracy: 0.8112\n",
      "Epoch 165/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4579 - accuracy: 0.8165 - val_loss: 0.4609 - val_accuracy: 0.8116\n",
      "Epoch 166/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4591 - accuracy: 0.8147 - val_loss: 0.4607 - val_accuracy: 0.8116\n",
      "Epoch 167/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4594 - accuracy: 0.8137 - val_loss: 0.4603 - val_accuracy: 0.8114\n",
      "Epoch 168/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4584 - accuracy: 0.8154 - val_loss: 0.4625 - val_accuracy: 0.8118\n",
      "Epoch 169/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4601 - accuracy: 0.8154 - val_loss: 0.4598 - val_accuracy: 0.8143\n",
      "Epoch 170/1000\n",
      "649/649 [==============================] - 10s 15ms/step - loss: 0.4587 - accuracy: 0.8138 - val_loss: 0.4589 - val_accuracy: 0.8125\n",
      "Epoch 171/1000\n",
      "649/649 [==============================] - 11s 18ms/step - loss: 0.4603 - accuracy: 0.8140 - val_loss: 0.4580 - val_accuracy: 0.8127\n",
      "Epoch 172/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4601 - accuracy: 0.8144 - val_loss: 0.4592 - val_accuracy: 0.8129\n",
      "Epoch 173/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4594 - accuracy: 0.8150 - val_loss: 0.4662 - val_accuracy: 0.8129\n",
      "Epoch 174/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4585 - accuracy: 0.8171 - val_loss: 0.4607 - val_accuracy: 0.8112\n",
      "Epoch 175/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4578 - accuracy: 0.8146 - val_loss: 0.4597 - val_accuracy: 0.8121\n",
      "Epoch 176/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4605 - accuracy: 0.8141 - val_loss: 0.4619 - val_accuracy: 0.8123\n",
      "Epoch 177/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4582 - accuracy: 0.8157 - val_loss: 0.4593 - val_accuracy: 0.8114\n",
      "Epoch 178/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4589 - accuracy: 0.8153 - val_loss: 0.4612 - val_accuracy: 0.8132\n",
      "Epoch 179/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4571 - accuracy: 0.8162 - val_loss: 0.4579 - val_accuracy: 0.8125\n",
      "Epoch 180/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4580 - accuracy: 0.8163 - val_loss: 0.4606 - val_accuracy: 0.8132\n",
      "Epoch 181/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4589 - accuracy: 0.8149 - val_loss: 0.4597 - val_accuracy: 0.8118\n",
      "Epoch 182/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4585 - accuracy: 0.8158 - val_loss: 0.4609 - val_accuracy: 0.8118\n",
      "Epoch 183/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4592 - accuracy: 0.8139 - val_loss: 0.4570 - val_accuracy: 0.8123\n",
      "Epoch 184/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4582 - accuracy: 0.8153 - val_loss: 0.4588 - val_accuracy: 0.8123\n",
      "Epoch 185/1000\n",
      "649/649 [==============================] - 11s 18ms/step - loss: 0.4593 - accuracy: 0.8140 - val_loss: 0.4588 - val_accuracy: 0.8121\n",
      "Epoch 186/1000\n",
      "649/649 [==============================] - 11s 18ms/step - loss: 0.4589 - accuracy: 0.8145 - val_loss: 0.4587 - val_accuracy: 0.8112\n",
      "Epoch 187/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4590 - accuracy: 0.8141 - val_loss: 0.4624 - val_accuracy: 0.8123\n",
      "Epoch 188/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4588 - accuracy: 0.8132 - val_loss: 0.4585 - val_accuracy: 0.8112\n",
      "Epoch 189/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4606 - accuracy: 0.8122 - val_loss: 0.4610 - val_accuracy: 0.8118\n",
      "Epoch 190/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4586 - accuracy: 0.8153 - val_loss: 0.4582 - val_accuracy: 0.8121\n",
      "Epoch 191/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4580 - accuracy: 0.8158 - val_loss: 0.4603 - val_accuracy: 0.8105\n",
      "Epoch 192/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4590 - accuracy: 0.8153 - val_loss: 0.4598 - val_accuracy: 0.8125\n",
      "Epoch 193/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4588 - accuracy: 0.8147 - val_loss: 0.4619 - val_accuracy: 0.8129\n",
      "Epoch 194/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4591 - accuracy: 0.8149 - val_loss: 0.4589 - val_accuracy: 0.8085\n",
      "Epoch 195/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4594 - accuracy: 0.8147 - val_loss: 0.4594 - val_accuracy: 0.8114\n",
      "Epoch 196/1000\n",
      "649/649 [==============================] - 12s 18ms/step - loss: 0.4579 - accuracy: 0.8138 - val_loss: 0.4595 - val_accuracy: 0.8121\n",
      "Epoch 197/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4608 - accuracy: 0.8124 - val_loss: 0.4580 - val_accuracy: 0.8114\n",
      "Epoch 198/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4598 - accuracy: 0.8142 - val_loss: 0.4578 - val_accuracy: 0.8127\n",
      "Epoch 199/1000\n",
      "649/649 [==============================] - 12s 18ms/step - loss: 0.4587 - accuracy: 0.8142 - val_loss: 0.4579 - val_accuracy: 0.8105\n",
      "Epoch 200/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4581 - accuracy: 0.8135 - val_loss: 0.4559 - val_accuracy: 0.8132\n",
      "Epoch 201/1000\n",
      "649/649 [==============================] - 11s 18ms/step - loss: 0.4583 - accuracy: 0.8166 - val_loss: 0.4599 - val_accuracy: 0.8109\n",
      "Epoch 202/1000\n",
      "649/649 [==============================] - 10s 15ms/step - loss: 0.4587 - accuracy: 0.8150 - val_loss: 0.4578 - val_accuracy: 0.8123\n",
      "Epoch 203/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4601 - accuracy: 0.8114 - val_loss: 0.4601 - val_accuracy: 0.8123\n",
      "Epoch 204/1000\n",
      "649/649 [==============================] - 12s 18ms/step - loss: 0.4574 - accuracy: 0.8166 - val_loss: 0.4583 - val_accuracy: 0.8121\n",
      "Epoch 205/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4592 - accuracy: 0.8139 - val_loss: 0.4587 - val_accuracy: 0.8125\n",
      "Epoch 206/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4576 - accuracy: 0.8151 - val_loss: 0.4580 - val_accuracy: 0.8121\n",
      "Epoch 207/1000\n",
      "649/649 [==============================] - 11s 18ms/step - loss: 0.4582 - accuracy: 0.8155 - val_loss: 0.4581 - val_accuracy: 0.8136\n",
      "Epoch 208/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4586 - accuracy: 0.8154 - val_loss: 0.4595 - val_accuracy: 0.8123\n",
      "Epoch 209/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4583 - accuracy: 0.8150 - val_loss: 0.4586 - val_accuracy: 0.8118\n",
      "Epoch 210/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4555 - accuracy: 0.8163 - val_loss: 0.4591 - val_accuracy: 0.8129\n",
      "Epoch 211/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4578 - accuracy: 0.8160 - val_loss: 0.4592 - val_accuracy: 0.8132\n",
      "Epoch 212/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4603 - accuracy: 0.8147 - val_loss: 0.4579 - val_accuracy: 0.8114\n",
      "Epoch 213/1000\n",
      "649/649 [==============================] - 12s 18ms/step - loss: 0.4570 - accuracy: 0.8153 - val_loss: 0.4591 - val_accuracy: 0.8116\n",
      "Epoch 214/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4588 - accuracy: 0.8146 - val_loss: 0.4588 - val_accuracy: 0.8118\n",
      "Epoch 215/1000\n",
      "649/649 [==============================] - 12s 18ms/step - loss: 0.4588 - accuracy: 0.8144 - val_loss: 0.4573 - val_accuracy: 0.8105\n",
      "Epoch 216/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4563 - accuracy: 0.8175 - val_loss: 0.4595 - val_accuracy: 0.8118\n",
      "Epoch 217/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4569 - accuracy: 0.8170 - val_loss: 0.4592 - val_accuracy: 0.8132\n",
      "Epoch 218/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4586 - accuracy: 0.8153 - val_loss: 0.4610 - val_accuracy: 0.8118\n",
      "Epoch 219/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4593 - accuracy: 0.8147 - val_loss: 0.4595 - val_accuracy: 0.8103\n",
      "Epoch 220/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4591 - accuracy: 0.8132 - val_loss: 0.4588 - val_accuracy: 0.8121\n",
      "Epoch 221/1000\n",
      "649/649 [==============================] - 12s 18ms/step - loss: 0.4582 - accuracy: 0.8158 - val_loss: 0.4573 - val_accuracy: 0.8129\n",
      "Epoch 222/1000\n",
      "649/649 [==============================] - 12s 18ms/step - loss: 0.4588 - accuracy: 0.8142 - val_loss: 0.4593 - val_accuracy: 0.8132\n",
      "Epoch 223/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4587 - accuracy: 0.8144 - val_loss: 0.4579 - val_accuracy: 0.8116\n",
      "Epoch 224/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4581 - accuracy: 0.8137 - val_loss: 0.4587 - val_accuracy: 0.8114\n",
      "Epoch 225/1000\n",
      "649/649 [==============================] - 12s 19ms/step - loss: 0.4562 - accuracy: 0.8186 - val_loss: 0.4579 - val_accuracy: 0.8132\n",
      "Epoch 226/1000\n",
      "649/649 [==============================] - 12s 18ms/step - loss: 0.4590 - accuracy: 0.8146 - val_loss: 0.4581 - val_accuracy: 0.8121\n",
      "Epoch 227/1000\n",
      "649/649 [==============================] - 12s 19ms/step - loss: 0.4594 - accuracy: 0.8127 - val_loss: 0.4580 - val_accuracy: 0.8116\n",
      "Epoch 228/1000\n",
      "649/649 [==============================] - 10s 15ms/step - loss: 0.4563 - accuracy: 0.8153 - val_loss: 0.4596 - val_accuracy: 0.8116\n",
      "Epoch 229/1000\n",
      "649/649 [==============================] - 11s 18ms/step - loss: 0.4575 - accuracy: 0.8153 - val_loss: 0.4576 - val_accuracy: 0.8123\n",
      "Epoch 230/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4577 - accuracy: 0.8181 - val_loss: 0.4600 - val_accuracy: 0.8127\n",
      "Epoch 231/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4595 - accuracy: 0.8123 - val_loss: 0.4577 - val_accuracy: 0.8116\n",
      "Epoch 232/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4575 - accuracy: 0.8151 - val_loss: 0.4583 - val_accuracy: 0.8105\n",
      "Epoch 233/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4601 - accuracy: 0.8144 - val_loss: 0.4589 - val_accuracy: 0.8121\n",
      "Epoch 234/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4567 - accuracy: 0.8168 - val_loss: 0.4604 - val_accuracy: 0.8127\n",
      "Epoch 235/1000\n",
      "649/649 [==============================] - 11s 18ms/step - loss: 0.4580 - accuracy: 0.8177 - val_loss: 0.4587 - val_accuracy: 0.8105\n",
      "Epoch 236/1000\n",
      "649/649 [==============================] - 12s 18ms/step - loss: 0.4569 - accuracy: 0.8158 - val_loss: 0.4591 - val_accuracy: 0.8123\n",
      "Epoch 237/1000\n",
      "649/649 [==============================] - 13s 19ms/step - loss: 0.4586 - accuracy: 0.8133 - val_loss: 0.4604 - val_accuracy: 0.8116\n",
      "Epoch 238/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4569 - accuracy: 0.8167 - val_loss: 0.4587 - val_accuracy: 0.8127\n",
      "Epoch 239/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4578 - accuracy: 0.8147 - val_loss: 0.4582 - val_accuracy: 0.8116\n",
      "Epoch 240/1000\n",
      "649/649 [==============================] - 11s 16ms/step - loss: 0.4562 - accuracy: 0.8152 - val_loss: 0.4617 - val_accuracy: 0.8118\n",
      "Epoch 241/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4585 - accuracy: 0.8143 - val_loss: 0.4573 - val_accuracy: 0.8132\n",
      "Epoch 242/1000\n",
      "649/649 [==============================] - 11s 18ms/step - loss: 0.4573 - accuracy: 0.8153 - val_loss: 0.4599 - val_accuracy: 0.8134\n",
      "Epoch 243/1000\n",
      "649/649 [==============================] - 12s 19ms/step - loss: 0.4565 - accuracy: 0.8168 - val_loss: 0.4583 - val_accuracy: 0.8132\n",
      "Epoch 244/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4577 - accuracy: 0.8155 - val_loss: 0.4584 - val_accuracy: 0.8138\n",
      "Epoch 245/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4577 - accuracy: 0.8153 - val_loss: 0.4589 - val_accuracy: 0.8121\n",
      "Epoch 246/1000\n",
      "649/649 [==============================] - 12s 18ms/step - loss: 0.4583 - accuracy: 0.8164 - val_loss: 0.4581 - val_accuracy: 0.8107\n",
      "Epoch 247/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4565 - accuracy: 0.8147 - val_loss: 0.4577 - val_accuracy: 0.8125\n",
      "Epoch 248/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4580 - accuracy: 0.8144 - val_loss: 0.4578 - val_accuracy: 0.8118\n",
      "Epoch 249/1000\n",
      "649/649 [==============================] - 10s 16ms/step - loss: 0.4579 - accuracy: 0.8148 - val_loss: 0.4572 - val_accuracy: 0.8121\n",
      "Epoch 250/1000\n",
      "649/649 [==============================] - 11s 17ms/step - loss: 0.4572 - accuracy: 0.8166 - val_loss: 0.4573 - val_accuracy: 0.8121\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkkAAAHFCAYAAADmGm0KAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACMgklEQVR4nOzdeVhU1f/A8ffMsO8CsogIuOG+oClgbqm4p2m5leZaZmVqtpiVpv0yzcystDQVNb8upZblivu+5paa4goiiKAwIrLO/f1xZXQCFXGZQT+v55kH5tx7zzn3gs6Hs2oURVEQQgghhBAmtOaugBBCCCGEJZIgSQghhBCiABIkCSGEEEIUQIIkIYQQQogCSJAkhBBCCFEACZKEEEIIIQogQZIQQgghRAEkSBJCCCGEKIAESUIIIYQQBZAgSYiHRKPRFOq1adOmBypn9OjRaDSaIl27adOmh1IHS9e7d28CAwPvePzy5cvY2NjQrVu3O56j1+txcHDg+eefL3S5kZGRaDQazp07V+i63E6j0TB69OhCl5fn4sWLjB49moMHD+Y79iC/Lw8qMDCQdu3amaVsIR4GK3NXQIgnxc6dO03ejx07lo0bN7JhwwaT9CpVqjxQOf3796dVq1ZFujYkJISdO3c+cB2Ku5IlS/L888/z+++/c/XqVUqUKJHvnIULF3Ljxg369ev3QGV98sknvPPOOw+Ux71cvHiRzz77jMDAQGrVqmVy7EF+X4R42kmQJMRDEhoaavK+ZMmSaLXafOn/lZ6ejoODQ6HLKV26NKVLly5SHV1cXO5Zn6dFv379WLJkCfPnz+ett97Kd3zWrFl4e3vTtm3bByqnXLlyD3T9g3qQ3xchnnbS3SbEY9SkSROqVavGli1bCA8Px8HBgb59+wKwaNEiIiIi8PX1xd7ensqVK/Phhx9y/fp1kzwK6j7J69ZYvXo1ISEh2NvbU6lSJWbNmmVyXkHdbb1798bJyYlTp07Rpk0bnJyc8Pf359133yUzM9Pk+gsXLvDiiy/i7OyMm5sbL7/8Mnv37kWj0RAZGXnXe798+TKDBg2iSpUqODk54eXlxXPPPcfWrVtNzjt37hwajYaJEycyadIkgoKCcHJyIiwsjF27duXLNzIykuDgYGxtbalcuTJz5869az3ytGzZktKlSzN79ux8x44fP87u3bvp1asXVlZWREVF0aFDB0qXLo2dnR3ly5fn9ddfJykp6Z7lFNTdptfrGTBgAB4eHjg5OdGqVStOnjyZ79pTp07Rp08fKlSogIODA35+frRv354jR44Yz9m0aRPPPPMMAH369DF26+Z12xX0+2IwGJgwYQKVKlXC1tYWLy8vevXqxYULF0zOy/t93bt3Lw0bNsTBwYGyZcvy5ZdfYjAY7nnvhZGRkcGIESMICgrCxsYGPz8/3nzzTVJSUkzO27BhA02aNMHDwwN7e3vKlClD586dSU9PN54zbdo0atasiZOTE87OzlSqVImPPvroodRTPJ2kJUmIxyw+Pp5XXnmF999/ny+++AKtVv1bJTo6mjZt2jBkyBAcHR35999/GT9+PHv27MnXZVeQQ4cO8e677/Lhhx/i7e3Nzz//TL9+/ShfvjyNGjW667XZ2dk8//zz9OvXj3fffZctW7YwduxYXF1d+fTTTwG4fv06TZs25cqVK4wfP57y5cuzevVqunbtWqj7vnLlCgCjRo3Cx8eHtLQ0li1bRpMmTVi/fj1NmjQxOf+HH36gUqVKTJ48GVC7rdq0acPZs2dxdXUF1ACpT58+dOjQga+//prU1FRGjx5NZmam8bneiVarpXfv3nz++eccOnSImjVrGo/lBU55Aezp06cJCwujf//+uLq6cu7cOSZNmsSzzz7LkSNHsLa2LtQzAFAUhY4dO7Jjxw4+/fRTnnnmGbZv307r1q3znXvx4kU8PDz48ssvKVmyJFeuXGHOnDnUr1+fAwcOEBwcTEhICLNnz6ZPnz58/PHHxpavu7UevfHGG0yfPp233nqLdu3ace7cOT755BM2bdrE33//jaenp/HchIQEXn75Zd59911GjRrFsmXLGDFiBKVKlaJXr16Fvu+7PYv169czYsQIGjZsyOHDhxk1ahQ7d+5k586d2Nracu7cOdq2bUvDhg2ZNWsWbm5uxMXFsXr1arKysnBwcGDhwoUMGjSIt99+m4kTJ6LVajl16hTHjh17oDqKp5wihHgkXn31VcXR0dEkrXHjxgqgrF+//q7XGgwGJTs7W9m8ebMCKIcOHTIeGzVqlPLff7oBAQGKnZ2dcv78eWPajRs3FHd3d+X11183pm3cuFEBlI0bN5rUE1AWL15skmebNm2U4OBg4/sffvhBAZRVq1aZnPf6668rgDJ79uy73tN/5eTkKNnZ2UqzZs2UF154wZh+9uxZBVCqV6+u5OTkGNP37NmjAMqCBQsURVGU3NxcpVSpUkpISIhiMBiM5507d06xtrZWAgIC7lmHM2fOKBqNRhk8eLAxLTs7W/Hx8VEaNGhQ4DV5P5vz588rgPLHH38Yj82ePVsBlLNnzxrTXn31VZO6rFq1SgGUb7/91iTf//u//1MAZdSoUXesb05OjpKVlaVUqFBBGTp0qDF97969d/wZ/Pf35fjx4wqgDBo0yOS83bt3K4Dy0UcfGdPyfl93795tcm6VKlWUli1b3rGeeQICApS2bdve8fjq1asVQJkwYYJJ+qJFixRAmT59uqIoivLbb78pgHLw4ME75vXWW28pbm5u96yTEPdDutuEeMxKlCjBc889ly/9zJkz9OjRAx8fH3Q6HdbW1jRu3BhQu3/upVatWpQpU8b43s7OjooVK3L+/Pl7XqvRaGjfvr1JWo0aNUyu3bx5M87OzvkGAXfv3v2e+ef58ccfCQkJwc7ODisrK6ytrVm/fn2B99e2bVt0Op1JfQBjnU6cOMHFixfp0aOHSXdSQEAA4eHhhapPUFAQTZs2Zf78+WRlZQGwatUqEhISjK1IAImJiQwcOBB/f39jvQMCAoDC/Wxut3HjRgBefvllk/QePXrkOzcnJ4cvvviCKlWqYGNjg5WVFTY2NkRHR993uf8tv3fv3ibp9erVo3Llyqxfv94k3cfHh3r16pmk/fd3o6jyWkj/W5eXXnoJR0dHY11q1aqFjY0Nr732GnPmzOHMmTP58qpXrx4pKSl0796dP/74o1BdoULciwRJQjxmvr6++dLS0tJo2LAhu3fv5vPPP2fTpk3s3buXpUuXAnDjxo175uvh4ZEvzdbWtlDXOjg4YGdnl+/ajIwM4/vk5GS8vb3zXVtQWkEmTZrEG2+8Qf369VmyZAm7du1i7969tGrVqsA6/vd+bG1tgVvPIjk5GVA/xP+roLQ76devH8nJySxfvhxQu9qcnJzo0qULoI7fiYiIYOnSpbz//vusX7+ePXv2GMdHFeb53i45ORkrK6t891dQnYcNG8Ynn3xCx44d+fPPP9m9ezd79+6lZs2a913u7eVDwb+HpUqVMh7P8yC/V4Wpi5WVFSVLljRJ12g0+Pj4GOtSrlw51q1bh5eXF2+++SblypWjXLlyfPvtt8ZrevbsyaxZszh//jydO3fGy8uL+vXrExUV9cD1FE8vGZMkxGNW0Jo1GzZs4OLFi2zatMnYegTkG7xqTh4eHuzZsydfekJCQqGu/+WXX2jSpAnTpk0zSb927VqR63On8gtbJ4BOnTpRokQJZs2aRePGjfnrr7/o1asXTk5OAPzzzz8cOnSIyMhIXn31VeN1p06dKnK9c3JySE5ONglACqrzL7/8Qq9evfjiiy9M0pOSknBzcyty+aCOjfvvuKWLFy+ajEd61PKexeXLl00CJUVRSEhIMA5IB2jYsCENGzYkNzeXffv28d133zFkyBC8vb2N61316dOHPn36cP36dbZs2cKoUaNo164dJ0+eNLb8CXE/pCVJCAuQFzjltZbk+emnn8xRnQI1btyYa9eusWrVKpP0hQsXFup6jUaT7/4OHz6cb32pwgoODsbX15cFCxagKIox/fz58+zYsaPQ+djZ2dGjRw/Wrl3L+PHjyc7ONulqe9g/m6ZNmwIwf/58k/T//e9/+c4t6JmtWLGCuLg4k7T/trLdTV5X7y+//GKSvnfvXo4fP06zZs3umcfDklfWf+uyZMkSrl+/XmBddDod9evX54cffgDg77//zneOo6MjrVu3ZuTIkWRlZXH06NFHUHvxNJCWJCEsQHh4OCVKlGDgwIGMGjUKa2tr5s+fz6FDh8xdNaNXX32Vb775hldeeYXPP/+c8uXLs2rVKtasWQNwz9lk7dq1Y+zYsYwaNYrGjRtz4sQJxowZQ1BQEDk5OfddH61Wy9ixY+nfvz8vvPACAwYMICUlhdGjR99XdxuoXW4//PADkyZNolKlSiZjmipVqkS5cuX48MMPURQFd3d3/vzzzyJ340RERNCoUSPef/99rl+/Tt26ddm+fTvz5s3Ld267du2IjIykUqVK1KhRg/379/PVV1/lawEqV64c9vb2zJ8/n8qVK+Pk5ESpUqUoVapUvjyDg4N57bXX+O6779BqtbRu3do4u83f35+hQ4cW6b7uJCEhgd9++y1femBgIC1atKBly5Z88MEH6PV6GjRoYJzdVrt2bXr27AmoY9k2bNhA27ZtKVOmDBkZGcblLZo3bw7AgAEDsLe3p0GDBvj6+pKQkMC4ceNwdXU1aZES4r6YeeC4EE+sO81uq1q1aoHn79ixQwkLC1McHByUkiVLKv3791f+/vvvfLOW7jS7raBZRI0bN1YaN25sfH+n2W3/reedyomJiVE6deqkODk5Kc7Ozkrnzp2VlStX5pvlVZDMzExl+PDhip+fn2JnZ6eEhIQov//+e77ZX3mz27766qt8eVDA7K+ff/5ZqVChgmJjY6NUrFhRmTVrVr48C6N27doFzrRSFEU5duyY0qJFC8XZ2VkpUaKE8tJLLykxMTH56lOY2W2KoigpKSlK3759FTc3N8XBwUFp0aKF8u+//+bL7+rVq0q/fv0ULy8vxcHBQXn22WeVrVu35vu5KoqiLFiwQKlUqZJibW1tkk9BP8fc3Fxl/PjxSsWKFRVra2vF09NTeeWVV5TY2FiT8+70+1rY5xsQEKAABb5effVVRVHUWZgffPCBEhAQoFhbWyu+vr7KG2+8oVy9etWYz86dO5UXXnhBCQgIUGxtbRUPDw+lcePGyvLly43nzJkzR2natKni7e2t2NjYKKVKlVK6dOmiHD58+J71FOJONIpyWzu1EELcpy+++IKPP/6YmJgYWdlZCPFEke42IUShff/994DaBZWdnc2GDRuYMmUKr7zyigRIQognjgRJQohCc3Bw4JtvvuHcuXNkZmZSpkwZPvjgAz7++GNzV00IIR466W4TQgghhCiALAEghBBCCFEACZKEEEIIIQogQZIQQgghRAFk4HYRGQwGLl68iLOzc4HbTAghhBDC8iiKwrVr1yhVqtQ9F8GVIKmILl68iL+/v7mrIYQQQogiiI2NvefSJRIkFZGzszOgPmQXFxcz10YIIYQQhaHX6/H39zd+jt+NBElFlNfF5uLiIkGSEEIIUcwUZqiMDNwWQgghhCiABElCCCGEEAWQIEkIIYQQogAyJkkIIYo5g8FAVlaWuashhEWwtrZGp9M9lLwkSBJCiGIsKyuLs2fPYjAYzF0VISyGm5sbPj4+D7yOoQRJQghRTCmKQnx8PDqdDn9//3sujCfEk05RFNLT00lMTATA19f3gfKTIEkIIYqpnJwc0tPTKVWqFA4ODuaujhAWwd7eHoDExES8vLweqOtN/uwQQohiKjc3FwAbGxsz10QIy5L3R0N2dvYD5SNBkhBCFHOyf6QQph7WvwkJkoQQQgghCiBBkhBCiCfOpk2b0Gg0pKSkFPqawMBAJk+e/MjqVJDevXvTsWPH+7pGo9Hw+++/P5L6CFMSJAkhhHisevfujUajYeDAgfmODRo0CI1GQ+/evR9/xe4iMDAQjUZzx1eTJk2KlO+3335LZGTkfV0THx9P69ati1Te/ZBgTGa3WZz0rByuXM/CxkqLl7OduasjhBCPhL+/PwsXLuSbb74xzkbKyMhgwYIFlClTxsy1y2/v3r3GgfI7duygc+fOnDhxwrjB+X8Hz2dnZ2NtbX3PfF1dXe+7Lj4+Pvd9jSgaaUmyMFHHLvHs+I0MWXjQ3FURQohHJiQkhDJlyrB06VJj2tKlS/H396d27dom52ZmZjJ48GC8vLyws7Pj2WefZe/evSbnrFy5kooVK2Jvb0/Tpk05d+5cvjJ37NhBo0aNsLe3x9/fn8GDB3P9+vVC1bdkyZL4+Pjg4+ODu7s7AF5eXsY0Dw8PfvzxRzp06ICjoyOff/45ubm59OvXj6CgIOzt7QkODubbb781yfe/3W1NmjRh8ODBvP/++7i7u+Pj48Po0aNNrrm9hefcuXNoNBqWLl1K06ZNcXBwoGbNmuzcudPkmhkzZuDv74+DgwMvvPACkyZNws3NrVD3XhCDwcCYMWMoXbo0tra21KpVi9WrVxuPZ2Vl8dZbb+Hr64udnR2BgYGMGzfOeHz06NGUKVMGW1tbSpUqxeDBg4tcl0dJgiQLo705It+gKGauiRCiuFEUhfSsHLO8lCL8n9WnTx9mz55tfD9r1iz69u2b77z333+fJUuWMGfOHP7++2/Kly9Py5YtuXLlCgCxsbF06tSJNm3acPDgQfr378+HH35okseRI0do2bIlnTp14vDhwyxatIht27bx1ltv3Xe972TUqFF06NCBI0eO0LdvXwwGA6VLl2bx4sUcO3aMTz/9lI8++ojFixffNZ85c+bg6OjI7t27mTBhAmPGjCEqKuqu14wcOZLhw4dz8OBBKlasSPfu3cnJyQFg+/btDBw4kHfeeYeDBw/SokUL/u///u+B7vXbb7/l66+/ZuLEiRw+fJiWLVvy/PPPEx0dDcCUKVNYvnw5ixcv5sSJE/zyyy8EBgYC8Ntvv/HNN9/w008/ER0dze+//0716tUfqD6PinS3WRhjkCQ7DAgh7tON7FyqfLrGLGUfG9MSB5v7+0jp2bMnI0aMMLaGbN++nYULF7Jp0ybjOdevX2fatGlERkYax+HMmDGDqKgoZs6cyXvvvce0adMoW7Ys33zzDRqNhuDgYI4cOcL48eON+Xz11Vf06NGDIUOGAFChQgWmTJlC48aNmTZtGnZ2Dz68oUePHvmCvM8++8z4fVBQEDt27GDx4sV06dLljvnUqFGDUaNGGev5/fffs379elq0aHHHa4YPH07btm2NZVatWpVTp05RqVIlvvvuO1q3bs3w4cMBqFixIjt27OCvv/4q8r1OnDiRDz74gG7dugEwfvx4Nm7cyOTJk/nhhx+IiYmhQoUKPPvss2g0GgICAozXxsTE4OPjQ/PmzbG2tqZMmTLUq1evyHV5lKQlycLobv5EcqUlSQjxhPP09KRt27bMmTOH2bNn07ZtWzw9PU3OOX36NNnZ2TRo0MCYZm1tTb169Th+/DgAx48fJzQ01GRtnLCwMJN89u/fT2RkJE5OTsZXy5YtMRgMnD179qHcT926dfOl/fjjj9StW5eSJUvi5OTEjBkziImJuWs+NWrUMHnv6+tr3GajMNfkbcWRd82JEyfyBSEPEpTo9XouXrxo8jMBaNCggfFn0rt3bw4ePEhwcDCDBw9m7dq1xvNeeuklbty4QdmyZRkwYADLli0ztnpZGmlJsjB5LUm5BgmShBD3x95ax7ExLc1WdlH07dvX2OX1ww8/5Due143338UBFUUxphWmq89gMPD6668XOPblYQ0Ud3R0NHm/ePFihg4dytdff01YWBjOzs589dVX7N69+675/HfAt0ajuecGxrdfozH2SKjX3P6s8hSle/S/7vYzCQkJ4ezZs6xatYp169bRpUsXmjdvzm+//Ya/vz8nTpwgKiqKdevWMWjQIL766is2b95cqMHuj5MESRZGpy38P3ohhLidRqO57y4vc2vVqhVZWVkAtGyZP8ArX748NjY2bNu2jR49egDqzLF9+/YZu86qVKmSb6r6rl27TN6HhIRw9OhRypcv//Bv4g62bt1KeHg4gwYNMqadPn36sZWfp1KlSuzZs8ckbd++fUXOz8XFhVKlSrFt2zYaNWpkTN+xY4dJC5WLiwtdu3ala9euvPjii7Rq1YorV67g7u6Ovb09zz//PM8//zxvvvkmlSpV4siRI4SEhBS5Xo9C8frX9BQwtiRJkCSEeArodDpjF01BG5E6Ojryxhtv8N577+Hu7k6ZMmWYMGEC6enp9OvXD4CBAwfy9ddfM2zYMF5//XVj19rtPvjgA0JDQ3nzzTcZMGAAjo6OHD9+nKioKL777rtHcm/ly5dn7ty5rFmzhqCgIObNm8fevXsJCgp6JOXdydtvv02jRo2YNGkS7du3Z8OGDaxatapQW3ecPXuWgwcPmqSVL1+e9957j1GjRlGuXDlq1arF7NmzOXjwIPPnzwfgm2++wdfXl1q1aqHVavn111/x8fHBzc2NyMhIcnNzqV+/Pg4ODsybNw97e3uTcUuWQoIkC6PV5nW3mbkiQgjxmOStNXQnX375JQaDgZ49e3Lt2jXq1q3LmjVrKFGiBKB2ly1ZsoShQ4cydepU6tWrxxdffGEyiLpGjRps3ryZkSNH0rBhQxRFoVy5cnTt2vWR3dfAgQM5ePAgXbt2RaPR0L17dwYNGsSqVaseWZkFadCgAT/++COfffYZH3/8MS1btmTo0KF8//3397x22LBh+dI2btzI4MGD0ev1vPvuuyQmJlKlShWWL19OhQoVAHBycmL8+PFER0ej0+l45plnWLlyJVqtFjc3N7788kuGDRtGbm4u1atX588//8TDw+Oh3/uD0ijSr1Mker0eV1dXUlNT7/kP/H5si07ilZm7CfZ2Zs3QRve+QAjx1MrIyODs2bMEBQU9lNlZ4ukxYMAA/v33X7Zu3WruqjwSd/u3cT+f39KSZGG0N2e3yTpJQgghHpaJEyfSokULHB0dWbVqFXPmzGHq1KnmrpbFkyDJwsiYJCGEEA/bnj17mDBhAteuXaNs2bJMmTKF/v37m7taFk+CJAuTN7vNIEsACCGEeEjutcq3KJjZF5OcOnWqsc+wTp069+wfzczMZOTIkQQEBGBra0u5cuWYNWuW8XhkZGSBOzRnZGQ8ULmPy61tScxcESGEEOIpZ9aWpEWLFjFkyBCmTp1KgwYN+Omnn2jdujXHjh274+JeXbp04dKlS8ycOZPy5cuTmJiYb6VOFxcXTpw4YZJ2+8CtopT7uNxsSJLFJIUQQggzM2uQNGnSJPr162fsF508eTJr1qxh2rRpJrsF51m9ejWbN2/mzJkzxl2Y8zbMu51Go8HHx+ehlfs4GbvbZEySEEIIYVZm627Lyspi//79REREmKRHRESwY8eOAq9Zvnw5devWZcKECfj5+VGxYkWGDx/OjRs3TM5LS0sjICCA0qVL065dOw4cOPBA5YLazafX601ej4JsSyKEEEJYBrO1JCUlJZGbm4u3t7dJure3NwkJCQVec+bMGbZt24adnR3Lli0jKSmJQYMGceXKFeO4pEqVKhEZGUn16tXR6/V8++23NGjQgEOHDlGhQoUilQswbtw4k92cH5VbLUmPvCghhBBC3IXZB27fbYO8/zIYDGg0GubPn0+9evVo06YNkyZNIjIy0tiaFBoayiuvvELNmjVp2LAhixcvpmLFivmWnb+fcgFGjBhBamqq8RUbG1uU272nWwO3JUoSQgghzMlsQZKnpyc6nS5f601iYmK+Vp48vr6++Pn54erqakyrXLkyiqJw4cKFAq/RarU888wzREdHF7lcAFtbW1xcXExej4Lu5k9EutuEEKLoNm3ahEajISUlpdDXBAYGMnny5EdWJ4DevXvTsWNH4/smTZoYN+p91PV6HPf3pDFbkGRjY0OdOnWIiooySY+KiiI8PLzAaxo0aMDFixdJS0szpp08eRKtVkvp0qULvEZRFA4ePIivr2+Ry32cjC1JEiQJIZ5QvXv3RqPRMHDgwHzHBg0ahEajoXfv3o+/Ynfx9ttvG/cl+6+4uDh0Oh1Lly6973yXLl3K2LFjH7R6JiIjI3Fzc8uXvnfvXl577bWHWtZ/FSU4tWRm7W4bNmwYP//8M7NmzeL48eMMHTqUmJgY4z+cESNG0KtXL+P5PXr0wMPDgz59+nDs2DG2bNnCe++9R9++fbG3twfgs88+Y82aNZw5c4aDBw/Sr18/Dh48aPKP8V7lmpPMbhNCPA38/f1ZuHChycSbjIwMFixYYPalWArSr18/Tp06VeCaepGRkXh4eNC+ffv7ztfd3R1nZ+eHUcV7KlmyJA4ODo+lrCeFWYOkrl27MnnyZMaMGUOtWrXYsmULK1euJCAgAID4+HhiYmKM5zs5OREVFUVKSgp169bl5Zdfpn379kyZMsV4TkpKCq+99hqVK1cmIiKCuLg4tmzZQr169QpdrjnJtiRCiKdBSEgIZcqUMWl9Wbp0Kf7+/tSuXdvk3MzMTAYPHoyXlxd2dnY8++yz7N271+SclStXUrFiRezt7WnatCnnzp3LV+aOHTto1KgR9vb2+Pv7M3jwYK5fv16o+taqVYuQkBCTxYvzREZG0qtXL7RaLf369SMoKAh7e3uCg4P59ttv75rvf7vbEhMTad++Pfb29gQFBTF//vx810yaNInq1avj6OiIv78/gwYNMvawbNq0iT59+pCammpcTHn06NFA/u62mJgYOnTogJOTEy4uLsZ1CPOMHj2aWrVqMW/ePAIDA3F1daVbt25cu3atUM+sIFevXqVXr16UKFECBwcHWrdubRwOA3D+/Hnat29PiRIlcHR0pGrVqqxcudJ47csvv0zJkiWxt7enQoUKzJ49u8h1KQyzb0syaNAgBg0aVOCxyMjIfGmVKlXK11V2u2+++YZvvvnmgco1J61xWxIzV0QIUfwoCmSnm6dsawe4y+SXgvTp04fZs2fz8ssvAzBr1iz69u3Lpk2bTM57//33WbJkCXPmzCEgIIAJEybQsmVLTp06hbu7O7GxsXTq1ImBAwfyxhtvsG/fPt59912TPI4cOULLli0ZO3YsM2fO5PLly7z11lu89dZbhf6g7devH++//z7fffcdTk5OAGzevJlTp07Rt29fDAYDpUuXZvHixXh6erJjxw5ee+01fH196dKlS6HK6N27N7GxsWzYsAEbGxsGDx5MYmKiyTlarZYpU6YQGBjI2bNnGTRoEO+//z5Tp04lPDycyZMn8+mnnxoXVc6r6+0URaFjx444OjqyefNmcnJyGDRoEF27djV5/qdPn+b333/nr7/+4urVq3Tp0oUvv/yS//u//yvU/RR0f9HR0SxfvhwXFxc++OAD2rRpw7Fjx7C2tubNN98kKyuLLVu24OjoyLFjx4z1/+STTzh27BirVq3C09OTU6dO5VsC6GEze5AkTOmkJUkIUVTZ6fBFKfOU/dFFsHG8r0t69uzJiBEjOHfuHBqNhu3bt7Nw4UKTD+nr168zbdo0IiMjad26NQAzZswgKiqKmTNn8t577zFt2jTKli3LN998g0ajITg4mCNHjjB+/HhjPl999RU9evQwttpUqFCBKVOm0LhxY6ZNm2ayK8Od9OjRg3fffZdff/2VPn36AGpgFxYWRpUqVQBMlooJCgpix44dLF68uFBB0smTJ1m1ahW7du2ifv36AMycOZPKlSubnHd7y1NQUBBjx47ljTfeYOrUqdjY2ODq6nrPRZXXrVvH4cOHOXv2LP7+/gDMmzePqlWrsnfvXp555hlAnVUeGRlp7BLs2bMn69evL1KQlBccbd++3TgGeP78+fj7+/P777/z0ksvERMTQ+fOnalevToAZcuWNV4fExND7dq1qVu3LlDwYtIPm9mXABCmtDd/IjImSQjxpPP09KRt27bMmTOH2bNn07ZtWzw9PU3OOX36NNnZ2TRo0MCYZm1tTb169Th+/DgAx48fJzQ01GQZl7CwMJN89u/fT2RkJE5OTsZXy5YtMRgMnD17tlD1dXNzo1OnTsYut2vXrrFkyRL69u1rPOfHH3+kbt26lCxZEicnJ2bMmGEybORujh8/jpWVlTEIALX35L+DsDdu3EiLFi3w8/PD2dmZXr16kZycXOiuw7yy/P39jQESQJUqVXBzczM+V1ADkdvHTPn6+uZr2bqfMq2srIwBIICHhwfBwcHGMgcPHsznn39OgwYNGDVqFIcPHzae+8Ybb7Bw4UJq1arF+++/f9cFoB8WaUmyMHljkhTl3ms3CSGECWsHtUXHXGUXQd++fXnrrbcA+OGHH/IdV27+wXi3te2UQvxRaTAYeP311xk8eHC+Y/czULxfv340a9aM6OhoNm/eDKjjXAEWL17M0KFD+frrrwkLC8PZ2ZmvvvqK3bt3FyrvO93r7c6fP0+bNm0YOHAgY8eOxd3dnW3bttGvXz+ys7MLfR93+nz5b7q1tbXJcY1Gg6GI40Hu9HO6vcz+/fvTsmVLVqxYwdq1axk3bhxff/01b7/9Nq1bt+b8+fOsWLGCdevW0axZM958800mTpxYpPoUhrQkWRjdbb+cslaSEOK+aDRql5c5XkX8g65Vq1ZkZWWRlZVFy5Yt8x0vX748NjY2bNu2zZiWnZ3Nvn37jN1QVapUYdeuXSbX/fd9SEgIR48epXz58vleNjY2ha5v06ZNKVu2LJGRkcyaNYsuXboYW1q2bt1KeHg4gwYNonbt2pQvX57Tp08XOu/KlSuTk5PDvn37jGknTpwwmU6/b98+cnJy+PrrrwkNDaVixYpcvGgaGNvY2JCbm3vXsqpUqUJMTIzJwsjHjh0jNTU1X/few1KlShVycnJMgsbk5GROnjxpUqa/vz8DBw5k6dKlvPvuu8yYMcN4rGTJkvTu3ZtffvmFyZMnM3369EdS1zzSkmRh8gZugzouSX5AQognmU6nM3a16HS6fMcdHR154403eO+993B3d6dMmTJMmDCB9PR0+vXrB8DAgQP5+uuvGTZsGK+//rqxa+12H3zwAaGhobz55psMGDAAR0dHjh8/TlRUVL4dGe5Go9HQp08fJk2axNWrV/nqq6+Mx8qXL8/cuXNZs2YNQUFBzJs3j7179xIUFFSovIODg2nVqhUDBgxg+vTpWFlZMWTIEOMSNwDlypUjJyeH7777jvbt27N9+3Z+/PFHk3wCAwNJS0tj/fr11KxZEwcHh3xT/5s3b06NGjV4+eWXmTx5snHgduPGjU26+4rqyJEj+ZY2qFWrFh06dGDAgAH89NNPODs78+GHH+Ln50eHDh0AdbxV69atqVixIlevXmXDhg3GAOrTTz+lTp06VK1alczMTP76669HFtDlkZYkC6O7LUiSYUlCiKfBvXYx+PLLL+ncuTM9e/YkJCSEU6dOsWbNGkqUKAGo3WVLlizhzz//pGbNmvz444988cUXJnnUqFGDzZs3Ex0dTcOGDalduzaffPKJcaHh+9G7d29SU1MJDg42GSs1cOBAOnXqRNeuXalfvz7Jycn3PYt69uzZ+Pv707hxYzp16sRrr72Gl5eX8XitWrWYNGkS48ePp1q1asyfP59x48aZ5BEeHs7AgQPp2rUrJUuWZMKECfnK0Wg0/P7775QoUYJGjRrRvHlzypYty6JFi+7zaRSsUaNG1K5d2+SVd3916tShXbt2hIWFoSgKK1euNHbr5ebm8uabb1K5cmVatWpFcHAwU6dOBdQWshEjRlCjRg0aNWqETqdj4cKFD6W+d6JRCtOZK/LR6/W4urqSmpr6ULcoSc/KocqnawA4+llLHG2lLUkIUbCMjAzOnj1LUFBQoWZnCfG0uNu/jfv5/JaWJAuj1Zh2twkhhBDCPCRIsjC3d7fJ/m1CCCGE+UiQZGFun90mMZIQQghhPhIkWZjbZ9HKEgBCCCGE+UiQZGE0Gg15PW6y6rYQojBk/o0Qph7WvwkJkixQ3rgkaUkSQtxN3rpCWVlZZq6JEJYlPV3d6Pm/K4bfL5lfboHUGW6KtCQJIe7KysoKBwcHLl++jLW1NVqt/N0rnm6KopCenk5iYiJubm4FLlB6PyRIskB5ywAUcXscIcRTQqPR4Ovry9mzZzl//ry5qyOExXBzc8PHx+eB85EgyQIZu9ukJUkIcQ82NjZUqFBButyEuMna2vqBW5DySJBkgWTgthDifmi1WllxW4hHQDqwLVBeS5IsJimEEEKYjwRJFihvTJJ0twkhhBDmI0GSBdLKEgBCCCGE2UmQZIHytiaRhiQhhBDCfCRIskCymKQQQghhfhIkWaC8/dtkTJIQQghhPhIkWSCZ3SaEEEKYnwRJFihvTJLESEIIIYT5SJBkgWR2mxBCCGF+EiRZIFlxWwghhDA/CZIskHExSWlJEkIIIcxGgiQLZBy4LS1JQgghhNlIkGSBJEgSQgghzM/sQdLUqVMJCgrCzs6OOnXqsHXr1ruen5mZyciRIwkICMDW1pZy5coxa9Ys4/EZM2bQsGFDSpQoQYkSJWjevDl79uwxyWP06NFoNBqTl4+PzyO5v6LQGLvbzFwRIYQQ4ilmZc7CFy1axJAhQ5g6dSoNGjTgp59+onXr1hw7dowyZcoUeE2XLl24dOkSM2fOpHz58iQmJpKTk2M8vmnTJrp37054eDh2dnZMmDCBiIgIjh49ip+fn/G8qlWrsm7dOuN7nU736G70PunyFpOUMUlCCCGE2Zg1SJo0aRL9+vWjf//+AEyePJk1a9Ywbdo0xo0bl+/81atXs3nzZs6cOYO7uzsAgYGBJufMnz/f5P2MGTP47bffWL9+Pb169TKmW1lZWVTr0e3yutsU6W4TQgghzMZs3W1ZWVns37+fiIgIk/SIiAh27NhR4DXLly+nbt26TJgwAT8/PypWrMjw4cO5cePGHctJT08nOzvbGFTliY6OplSpUgQFBdGtWzfOnDlz1/pmZmai1+tNXo+KcXabBElCCCGE2ZitJSkpKYnc3Fy8vb1N0r29vUlISCjwmjNnzrBt2zbs7OxYtmwZSUlJDBo0iCtXrpiMS7rdhx9+iJ+fH82bNzem1a9fn7lz51KxYkUuXbrE559/Tnh4OEePHsXDw6PAfMaNG8dnn31WxLu9P7IEgBBCCGF+Zh+4nTdIOY+iKPnS8hgMBjQaDfPnz6devXq0adOGSZMmERkZWWBr0oQJE1iwYAFLly7Fzs7OmN66dWs6d+5M9erVad68OStWrABgzpw5d6zniBEjSE1NNb5iY2OLcruFIrPbhBBCCPMzW0uSp6cnOp0uX6tRYmJivtalPL6+vvj5+eHq6mpMq1y5MoqicOHCBSpUqGBMnzhxIl988QXr1q2jRo0ad62Lo6Mj1atXJzo6+o7n2NraYmtrW5hbe2Ba4wa3j6U4IYQQQhTAbC1JNjY21KlTh6ioKJP0qKgowsPDC7ymQYMGXLx4kbS0NGPayZMn0Wq1lC5d2pj21VdfMXbsWFavXk3dunXvWZfMzEyOHz+Or69vEe/m4TLObpOWJCGEEMJszNrdNmzYMH7++WdmzZrF8ePHGTp0KDExMQwcOBBQu7hun5HWo0cPPDw86NOnD8eOHWPLli2899579O3bF3t7e0DtYvv444+ZNWsWgYGBJCQkkJCQYBJYDR8+nM2bN3P27Fl2797Niy++iF6v59VXX328D+AO8sYkGWRMkhBCCGE2Zl0CoGvXriQnJzNmzBji4+OpVq0aK1euJCAgAID4+HhiYmKM5zs5OREVFcXbb79N3bp18fDwoEuXLnz++efGc6ZOnUpWVhYvvviiSVmjRo1i9OjRAFy4cIHu3buTlJREyZIlCQ0NZdeuXcZyzc3Y3SYxkhBCCGE2GkUW4ykSvV6Pq6srqampuLi4PNS8B87bz+qjCYztWI2eoZYRuAkhhBBPgvv5/Db77DaRn3F2mzQlCSGEEGYjQZIF0si2JEIIIYTZSZBkgWSdJCGEEML8JEiyQDqNBElCCCGEuUmQZIE0xm1JzFwRIYQQ4ikmQZIF0t38qUhLkhBCCGE+EiRZIJndJoQQQpifBEkWKG/FbdmWRAghhDAfCZIskGxLIoQQQpifBEkWKK+7TVqShBBCCPORIMkCGVuSJEYSQgghzEaCJAtknN0mUZIQQghhNhIkWSDjwG0JkoQQQgizkSDJAmllTJIQQghhdhIkWaC8bUkkRhJCCCHMR4IkC2RsSZLuNiGEEMJsJEiyQDdjJOluE0IIIcxIgiQLpJPFJIUQQgizkyDJAuV1t8kGt0IIIYT5SJBkgYwrbhvMXBEhhBDiKSZBkgXKG5MkLUlCCCGE+UiQZIFkMUkhhBDC/CRIskA6GZMkhBBCmJ0ESRZIgiQhhBDC/CRIskAa6W4TQgghzE6CJAtkXCdJYiQhhBDCbCRIskC6mz8VWUxSCCGEMB8JkiyQcXabjEkSQgghzEaCJAskSwAIIYQQ5idBkgXKm90mDUlCCCGE+Zg9SJo6dSpBQUHY2dlRp04dtm7detfzMzMzGTlyJAEBAdja2lKuXDlmzZplcs6SJUuoUqUKtra2VKlShWXLlj1wuY+TVistSUIIIYS5mTVIWrRoEUOGDGHkyJEcOHCAhg0b0rp1a2JiYu54TZcuXVi/fj0zZ87kxIkTLFiwgEqVKhmP79y5k65du9KzZ08OHTpEz5496dKlC7t3736gch8nnYxJEkIIIcxOoyjm+ySuX78+ISEhTJs2zZhWuXJlOnbsyLhx4/Kdv3r1arp168aZM2dwd3cvMM+uXbui1+tZtWqVMa1Vq1aUKFGCBQsWFKncguj1elxdXUlNTcXFxaVQ1xTWqiPxvDH/b+oGlOC3N8Ifat5CCCHE0+x+Pr/N1pKUlZXF/v37iYiIMEmPiIhgx44dBV6zfPly6taty4QJE/Dz86NixYoMHz6cGzduGM/ZuXNnvjxbtmxpzLMo5T5uWllxWwghhDA7K3MVnJSURG5uLt7e3ibp3t7eJCQkFHjNmTNn2LZtG3Z2dixbtoykpCQGDRrElStXjOOSEhIS7ppnUcoFdSxUZmam8b1ery/8zd6nW91tj6wIIYQQQtyD2Qdu523BkUdRlHxpeQwGAxqNhvnz51OvXj3atGnDpEmTiIyMNGlNKkye91MuwLhx43B1dTW+/P39C3V/RWHcu00GbgshhBBmY7YgydPTE51Ol6/1JjExMV8rTx5fX1/8/PxwdXU1plWuXBlFUbhw4QIAPj4+d82zKOUCjBgxgtTUVOMrNja28Dd7n/JiNZndJoQQQpiP2YIkGxsb6tSpQ1RUlEl6VFQU4eEFD1Zu0KABFy9eJC0tzZh28uRJtFotpUuXBiAsLCxfnmvXrjXmWZRyAWxtbXFxcTF5PSo6GZMkhBBCmJ1Zu9uGDRvGzz//zKxZszh+/DhDhw4lJiaGgQMHAmrrTa9evYzn9+jRAw8PD/r06cOxY8fYsmUL7733Hn379sXe3h6Ad955h7Vr1zJ+/Hj+/fdfxo8fz7p16xgyZEihyzW3WxvcSpAkhBBCmIvZBm6DOl0/OTmZMWPGEB8fT7Vq1Vi5ciUBAQEAxMfHm6xd5OTkRFRUFG+//TZ169bFw8ODLl268PnnnxvPCQ8PZ+HChXz88cd88sknlCtXjkWLFlG/fv1Cl2tuspikEEIIYX5mXSepOHuU6yTtOXuFLj/tJMjTkY3DmzzUvIUQQoinWbFYJ0ncme7mT0W624QQQgjzkSDJAmk10t0mhBBCmJsESRZI1kkSQgghzE+CJAuklQ1uhRBCCLOTIMkCaY1LAJi5IkIIIcRTTIIkCyTdbUIIIYT5SZBkgfJmt0l3mxBCCGE+EiRZII3MbhNCCCHMToIkC5S3LYk0JAkhhBDmI0GSBdLJtiRCCCGE2UmQZIGMe7dJU5IQQghhNhIkWaCbMRKyrZ4QQghhPhIkWSCdDNwWQgghzE6CJAuU191mUKQ1SQghhDAXCZIsUN6K2yCrbgshhBDmIkGSBdKZBEkSJQkhhBDmIEGSBdLe9lORcUlCCCGEeUiQZIHy1kkCaUkSQgghzEWCJAt0+5gkaUkSQgghzEOCJAskA7eFEEII85MgyQKZdLdJlCSEEEKYhQRJFui2GEm2JhFCCCHMRIIkC6TRaMjrcZOWJCGEEMI8JEiyUHlrJUmMJIQQQpiHBEkWKm9rEuluE0IIIcxDgiQLZWxJkqYkIYQQwiwkSLJQeYO3ZZ0kIYQQwjwkSLJQed1tsuK2EEIIYR4SJFkonQRJQgghhFlJkGSh8sYk5RrMXBEhhBDiKSVBkoXSGIMkaUkSQgghzMHsQdLUqVMJCgrCzs6OOnXqsHXr1jueu2nTppsLLZq+/v33X+M5TZo0KfCctm3bGs8ZPXp0vuM+Pj6P9D7vl+7mT0a624QQQgjzsDJn4YsWLWLIkCFMnTqVBg0a8NNPP9G6dWuOHTtGmTJl7njdiRMncHFxMb4vWbKk8fulS5eSlZVlfJ+cnEzNmjV56aWXTPKoWrUq69atM77X6XQP45YemluLSUqQJIQQQpiDWYOkSZMm0a9fP/r37w/A5MmTWbNmDdOmTWPcuHF3vM7Lyws3N7cCj7m7u5u8X7hwIQ4ODvmCJCsrK4trPbqdcTFJ6W4TQgghzMJs3W1ZWVns37+fiIgIk/SIiAh27Nhx12tr166Nr68vzZo1Y+PGjXc9d+bMmXTr1g1HR0eT9OjoaEqVKkVQUBDdunXjzJkzd80nMzMTvV5v8nqUtLItiRBCCGFWZguSkpKSyM3Nxdvb2yTd29ubhISEAq/x9fVl+vTpLFmyhKVLlxIcHEyzZs3YsmVLgefv2bOHf/75x9hSlad+/frMnTuXNWvWMGPGDBISEggPDyc5OfmO9R03bhyurq7Gl7+//33e8f2RJQCEEEII8zJrdxvcmsWVR1GUfGl5goODCQ4ONr4PCwsjNjaWiRMn0qhRo3znz5w5k2rVqlGvXj2T9NatWxu/r169OmFhYZQrV445c+YwbNiwAsseMWKEyTG9Xv9IAyVZcVsIIYQwL7O1JHl6eqLT6fK1GiUmJuZrXbqb0NBQoqOj86Wnp6ezcOHCfK1IBXF0dKR69eoF5pPH1tYWFxcXk9ejZGxJkiBJCCGEMAuzBUk2NjbUqVOHqKgok/SoqCjCw8MLnc+BAwfw9fXNl7548WIyMzN55ZVX7plHZmYmx48fLzAfc5ExSUIIIYR5mbW7bdiwYfTs2ZO6desSFhbG9OnTiYmJYeDAgYDaxRUXF8fcuXMBdfZbYGAgVatWJSsri19++YUlS5awZMmSfHnPnDmTjh074uHhke/Y8OHDad++PWXKlCExMZHPP/8cvV7Pq6+++mhv+D7kBUm5MiZJCCGEMAuzBkldu3YlOTmZMWPGEB8fT7Vq1Vi5ciUBAQEAxMfHExMTYzw/KyuL4cOHExcXh729PVWrVmXFihW0adPGJN+TJ0+ybds21q5dW2C5Fy5coHv37iQlJVGyZElCQ0PZtWuXsVxLIN1tQgghhHlpFEWaKopCr9fj6upKamrqIxmf1OGH7RyKTeHnXnVpXqXwY7SEEEIIcWf38/lt9m1JRMHyZrfJEgBCCCGEeUiQZKFkWxIhhBDCvCRIslC3tiUxc0WEEEKIp5QESRZKJ7PbhBBCCLOSIMlCaW/+ZGRcvRBCCGEeEiRZKOM6SbIEgBBCCGEWEiRZKJ1WgiQhhBDCnCRIslAyu00IIYQwLwmSLJRG9m4TQgghzEqCJAulu/mTke42IYQQwjyKFCTFxsZy4cIF4/s9e/YwZMgQpk+f/tAq9rQz7t0m3W1CCCGEWRQpSOrRowcbN24EICEhgRYtWrBnzx4++ugjxowZ81Ar+LSS2W1CCCGEeRUpSPrnn3+oV68eAIsXL6ZatWrs2LGD//3vf0RGRj7M+j21tDImSQghhDCrIgVJ2dnZ2NraArBu3Tqef/55ACpVqkR8fPzDq91TzNjdJlGSEEIIYRZFCpKqVq3Kjz/+yNatW4mKiqJVq1YAXLx4EQ8Pj4dawaeVVrYlEUIIIcyqSEHS+PHj+emnn2jSpAndu3enZs2aACxfvtzYDScejMxuE0IIIczLqigXNWnShKSkJPR6PSVKlDCmv/baazg4ODy0yj3N8lqSZO82IYQQwjyK1JJ048YNMjMzjQHS+fPnmTx5MidOnMDLy+uhVvBppTVuS2LmigghhBBPqSIFSR06dGDu3LkApKSkUL9+fb7++ms6duzItGnTHmoFn1Y6GZMkhBBCmFWRgqS///6bhg0bAvDbb7/h7e3N+fPnmTt3LlOmTHmoFXxa5c1uk+42IYQQwjyKFCSlp6fj7OwMwNq1a+nUqRNarZbQ0FDOnz//UCv4tLrZkCQDt4UQQggzKVKQVL58eX7//XdiY2NZs2YNERERACQmJuLi4vJQK/i0ku42IYQQwryKFCR9+umnDB8+nMDAQOrVq0dYWBigtirVrl37oVbwaSWLSQohhBDmVaQlAF588UWeffZZ4uPjjWskATRr1owXXnjhoVXuaWZrrQMgI1umtwkhhBDmUKQgCcDHxwcfHx8uXLiARqPBz89PFpJ8iJxt1R/NtYxsM9dECCGEeDoVqbvNYDAwZswYXF1dCQgIoEyZMri5uTF27FgMBmn5eBic7fKCpBwz10QIIYR4OhWpJWnkyJHMnDmTL7/8kgYNGqAoCtu3b2f06NFkZGTwf//3fw+7nk8dZztrQIIkIYQQwlyKFCTNmTOHn3/+meeff96YVrNmTfz8/Bg0aJAESQ9BXkuSXrrbhBBCCLMoUnfblStXqFSpUr70SpUqceXKlQeulJDuNiGEEMLcihQk1axZk++//z5f+vfff0+NGjUeuFLi9u42aUkSQgghzKFIQdKECROYNWsWVapUoV+/fvTv358qVaoQGRnJxIkT7yuvqVOnEhQUhJ2dHXXq1GHr1q13PHfTpk1oNJp8r3///dd4TmRkZIHnZGRkFLlcc8hrSUrLzJGtSYQQQggzKFKQ1LhxY06ePMkLL7xASkoKV65coVOnThw9epTZs2cXOp9FixYxZMgQRo4cyYEDB2jYsCGtW7cmJibmrtedOHGC+Ph446tChQomx11cXEyOx8fHY2dn98DlPk55QZJBgfSsXDPXRgghhHj6aJSH2Exx6NAhQkJCyM0t3Id6/fr1CQkJYdq0aca0ypUr07FjR8aNG5fv/E2bNtG0aVOuXr2Km5tbgXlGRkYyZMgQUlJSHlq5BdHr9bi6upKamvpItmJRFIXyI1eRa1DYNaIZPq52975ICCGEEHd1P5/fRWpJehiysrLYv3+/cd+3PBEREezYseOu19auXRtfX1+aNWvGxo0b8x1PS0sjICCA0qVL065dOw4cOPDA5WZmZqLX601ej5JGo7lt8LaMSxJCCCEeN7MFSUlJSeTm5uLt7W2S7u3tTUJCQoHX+Pr6Mn36dJYsWcLSpUsJDg6mWbNmbNmyxXhOpUqViIyMZPny5SxYsAA7OzsaNGhAdHR0kcsFGDduHK6ursaXv79/UW/97k6uhelN4K+hty0DIDPchBBCiMetyNuSPCyam7vd51EUJV9anuDgYIKDg43vw8LCiI2NZeLEiTRq1AiA0NBQQkNDjec0aNCAkJAQvvvuO6ZMmVKkcgFGjBjBsGHDjO/1ev2jCZSyr8PFA2DtgLNtJ+CGtCQJIYQQZnBfQVKnTp3uevxu44D+y9PTE51Ol6/1JjExMV8rz92Ehobyyy+/3PG4VqvlmWeeMbYkFbVcW1tbbG1tC12vIrN1Vr9m6nGStZKEEEIIs7mv7rbbu5sKegUEBNCrV69C5WVjY0OdOnWIiooySY+KiiI8PLzQdTpw4AC+vr53PK4oCgcPHjSe87DKfWRsXdWvGXpcJEgSQgghzOa+WpLuZ3p/YQwbNoyePXtSt25dwsLCmD59OjExMQwcOBBQu7ji4uKYO3cuAJMnTyYwMJCqVauSlZXFL7/8wpIlS1iyZIkxz88++4zQ0FAqVKiAXq9nypQpHDx4kB9++KHQ5ZqVsSXpmnFBybRM6W4TQgghHjezjknq2rUrycnJjBkzhvj4eKpVq8bKlSsJCAgAID4+3mTtoqysLIYPH05cXBz29vZUrVqVFStW0KZNG+M5KSkpvPbaayQkJODq6krt2rXZsmUL9erVK3S5ZnV7kGSrA6QlSQghhDCHh7pO0tPkka2TlKGHL9UB4ZPqb2HK5gv0Dg9k9PNVH14ZQgghxFOqWKyTJO7AxglQZ9m56zIB0MvsNiGEEOKxkyDJ0mi1xi63Ejp1vznpbhNCCCEePwmSLNHNIMnVGCRJS5IQQgjxuEmQZInygiSNtCQJIYQQ5iJBkiWyVQeSOZMOQFqmBElCCCHE4yZBkiW62ZLkyA1AWpKEEEIIc5AgyRLdDJLsleuAOiZJVmoQQgghHi8JkizRzSDJzqB2t2XnKmTmGMxZIyGEEOKpI0GSJbJT92+zzUlDoy6ZJGslCSGEEI+ZBEmW6GZLkibrGk42ssmtEEIIYQ4SJFkik01uJUgSQgghzEGCJEt0cwkAMvQ421kDkCZBkhBCCPFYSZBkiW5rSXIytiTJmCQhhBDicZIgyRLdFiS5O9oAcDkt04wVEkIIIZ4+EiRZorzutkw9ZdwdADifnG7GCgkhhBBPHwmSLJHdrSApwEOCJCGEEMIcJEiyRLd1t5UpYQ9AzJXrZqyQEEII8fSRIMkS5QVJhhwC3XQAxFxJl61JhBBCiMdIgiRLZO0IqEttl7LLQauBjGwDiddk8LYQQgjxuEiQZIm0WuPgbZucNEq5qV1uMi5JCCGEeHwkSLJUxnFJtwZvn0uWcUlCCCHE4yJBkqW6bfB2gIcjADHSkiSEEEI8NhIkWarbW5Ly1kq6IkGSEEII8bhIkGSpjGslXTN2t8VId5sQQgjx2EiQZKluXyvJXe1uk5YkIYQQ4vGRIMlS3dbdVuZmS1JKejapN2SjWyGEEOJxkCDJUuXt35Z+FSdbKzxubnQbK61JQgghxGMhQZKlKhmsfo0/pL51tgUgKU0WlBRCCCEeBwmSLJV/ffVr3H7Izb4tSMoyY6WEEEKIp4cESZbKowLYuUHODUg4gqeTtCQJIYQQj5PZg6SpU6cSFBSEnZ0dderUYevWrXc8d9OmTWg0mnyvf//913jOjBkzaNiwISVKlKBEiRI0b96cPXv2mOQzevTofHn4+Pg8snssEq0W/Oup38fuMbYkXZb924QQQojHwqxB0qJFixgyZAgjR47kwIEDNGzYkNatWxMTE3PX606cOEF8fLzxVaFCBeOxTZs20b17dzZu3MjOnTspU6YMERERxMXFmeRRtWpVkzyOHDnySO7xgRiDpN14OqkDt6UlSQghhHg8rMxZ+KRJk+jXrx/9+/cHYPLkyaxZs4Zp06Yxbty4O17n5eWFm5tbgcfmz59v8n7GjBn89ttvrF+/nl69ehnTraysLK/16L/yxiXF7sGznHS3CSGEEI+T2VqSsrKy2L9/PxERESbpERER7Nix467X1q5dG19fX5o1a8bGjRvvem56ejrZ2dm4u7ubpEdHR1OqVCmCgoLo1q0bZ86cuWs+mZmZ6PV6k9cjVyoENDrQX8BPmwxId5sQQgjxuJgtSEpKSiI3Nxdvb2+TdG9vbxISEgq8xtfXl+nTp7NkyRKWLl1KcHAwzZo1Y8uWLXcs58MPP8TPz4/mzZsb0+rXr8/cuXNZs2YNM2bMICEhgfDwcJKTk++Yz7hx43B1dTW+/P397/OOi8DWCXyqAVDu7AJAZrcJIYQQj4tZu9sANBqNyXtFUfKl5QkODiY4ONj4PiwsjNjYWCZOnEijRo3ynT9hwgQWLFjApk2bsLOzM6a3bt3a+H316tUJCwujXLlyzJkzh2HDhhVY9ogRI0yO6fX6xxMohb0FSwfgeWgar+gymJ/egpxcA1Y6s4+5F0IIIZ5oZvuk9fT0RKfT5Ws1SkxMzNe6dDehoaFER0fnS584cSJffPEFa9eupUaNGnfNw9HRkerVqxeYTx5bW1tcXFxMXo9FjS7Q5CMARlvNoaRylSvXpTVJCCGEeNTMFiTZ2NhQp04doqKiTNKjoqIIDw8vdD4HDhzA19fXJO2rr75i7NixrF69mrp1694zj8zMTI4fP54vH4vR+H3wqICVxkCwNpZEGZckhBBCPHJm7W4bNmwYPXv2pG7duoSFhTF9+nRiYmIYOHAgoHZxxcXFMXfuXECd/RYYGEjVqlXJysril19+YcmSJSxZssSY54QJE/jkk0/43//+R2BgoLGlysnJCScnJwCGDx9O+/btKVOmDImJiXz++efo9XpeffXVx/wECkmjAfeykBxNac1lmeEmhBBCPAZmDZK6du1KcnIyY8aMIT4+nmrVqrFy5UoCAgIAiI+PN1kzKSsri+HDhxMXF4e9vT1Vq1ZlxYoVtGnTxnjO1KlTycrK4sUXXzQpa9SoUYwePRqACxcu0L17d5KSkihZsiShoaHs2rXLWK5FcisDcDNIku42IYQQ4lHTKIqimLsSxZFer8fV1ZXU1NTHMz5p+xSI+oQ/csO52Ox73mhS7tGXKYQQQjxh7ufzW6ZIFRcmLUnS3SaEEEI8ahIkFRcSJAkhhBCPlQRJxYWbOl7KW5NC6rVrZq6MEEII8eSTIKm4cHAn18oBAE3qBTNXRgghhHjySZBUXGg0ZLuoK3zbp8eZuTJCCCHEk0+CpGJEW0LtcnPNjCcjO9fMtRFCCCGebBIkFSPW7mqQ5K+5zMWUG2aujRBCCPFkkyCpGNHcbEkqrblM7FUJkoQQQohHSYKk4uS2ZQBir6SbuTJCCCHEk02CpOLEGCQlcUFakoQQQohHSoKk4sRVDZK8NCnEJ6eYty5CCCHEE06CpOLEwZ1crQ0A6cmyVpIQQgjxKEmQVJxoNOQ6+gCQm3rRzJURQgghnmwSJBUzWtdSADhkJHI9M8fMtRFCCCGeXBIkFTNWbn4A+GiuyOBtIYQQ4hGSIKm4cVFbknw0V2QZACGEEOIRkiCpuHHOC5KucuGqBElCCCHEoyJBUnHj4gvcbEmS7jYhhBDikZEgqbhxuTUmSbrbhBBCiEdHgqTixlltSfLiKmcS9WaujBBCCPHkkiCpuHH2QUGDjSaXlKQEUtKzzF0jIYQQ4okkQVJxo7NG4+QFgLfmCgdiUsxbHyGEEOIJJUFSceR8a/D2vvNXzFwZIYQQ4skkQVJxdHOtJF/NFfadu2rmygghhBBPJgmSiqObQZK35iqHLqSQnWswc4WEEEKIJ48EScXRze62MlYpZGQbOHZRZrkJIYQQD5sEScXRzZak8nZqcLT/vHS5CSGEEA+bBEnFkVsZAEpzCYC/YyRIEkIIIR42CZKKo5KVAHDNiMOeDI7EpZq5QkIIIcSTR4Kk4sjRExxLAlBBE8f55HRZVFIIIYR4yMweJE2dOpWgoCDs7OyoU6cOW7duveO5mzZtQqPR5Hv9+++/JuctWbKEKlWqYGtrS5UqVVi2bNkDlWuRbrYmhTsnAnD4grQmCSGEEA+TWYOkRYsWMWTIEEaOHMmBAwdo2LAhrVu3JiYm5q7XnThxgvj4eOOrQoUKxmM7d+6ka9eu9OzZk0OHDtGzZ0+6dOnC7t27H7hci+JVBYC6jnlBUooZKyOEEEI8eTSKoijmKrx+/fqEhIQwbdo0Y1rlypXp2LEj48aNy3f+pk2baNq0KVevXsXNza3APLt27Yper2fVqlXGtFatWlGiRAkWLFhQpHILotfrcXV1JTU1FRcXl0Jd81DtmwV/DSXWI5yGcW8RUcWb6b3qPv56CCGEEMXI/Xx+m60lKSsri/379xMREWGSHhERwY4dO+56be3atfH19aVZs2Zs3LjR5NjOnTvz5dmyZUtjng9SrkW52ZLklXEOkO42IYQQ4mGzMlfBSUlJ5Obm4u3tbZLu7e1NQkJCgdf4+voyffp06tSpQ2ZmJvPmzaNZs2Zs2rSJRo0aAZCQkHDXPItSLkBmZiaZmZnG93q9mRdwvDkmyfb6RVw16SToIVGfgZeLnXnrJYQQQjwhzBYk5dFoNCbvFUXJl5YnODiY4OBg4/uwsDBiY2OZOHGiMUgqbJ73Uy7AuHHj+Oyzz+5+M4+TvZu68va1eJq4X+GPZAcOXUilRRUJkoQQQoiHwWzdbZ6enuh0unytN4mJiflaee4mNDSU6Oho43sfH5+75lnUckeMGEFqaqrxFRsbW+g6PjJelQEId74MwIkE2Z5ECCGEeFjMFiTZ2NhQp04doqKiTNKjoqIIDw8vdD4HDhzA19fX+D4sLCxfnmvXrjXmWdRybW1tcXFxMXmZXUk1SKqkUwO2M5evm7M2QgghxBPFrN1tw4YNo2fPntStW5ewsDCmT59OTEwMAwcOBNTWm7i4OObOnQvA5MmTCQwMpGrVqmRlZfHLL7+wZMkSlixZYszznXfeoVGjRowfP54OHTrwxx9/sG7dOrZt21bocosNn+oAlMk4CcDpy2nmrI0QQgjxRDFrkNS1a1eSk5MZM2YM8fHxVKtWjZUrVxIQEABAfHy8ydpFWVlZDB8+nLi4OOzt7alatSorVqygTZs2xnPCw8NZuHAhH3/8MZ988gnlypVj0aJF1K9fv9DlFht+dQBwTT2GjlzOXL5+z7FVQgghhCgcs66TVJyZfZ0kAIMBxgdApp42WV9yzFCGPR81kxluQgghxB0Ui3WSxEOg1YJvTQCaOKnjkk7LuCQhhBDioZAgqbi72eVWz+YcIOOShBBCiIdFgqTizi8EgGCDugyCzHATQgghHg4Jkoq7UmqQ5H3jNLZkcSZJWpKEEEKIh8HsK26LB+RaGhy90F5PZL3tcNJjnCFjC9hZwDpOQgghRDEmLUnFnUYD/vUAKK1JoqJylqxzu8xcKSGEEKL4kyDpSdBiDErjDzlJGQCS4s+buUJCCCFE8SdB0pPAoxyapiOIsasEQGpizD0uEEIIIcS9SJD0BNG6qHvY3bgSZ+aaCCGEEMWfBElPEEeP0uo3+njzVkQIIYR4AkiQ9AQp4aOOSbLLSDRzTYQQQojiT4KkJ0gp/7IAlDBcITU928y1EUIIIYo3CZKeIE6e/gCUJIUT8SnmrYwQQghRzEmQ9CRxLIkBLVYaA+diZRkAIYQQ4kFIkPQk0VmRbu0OwKUL58xbFyGEEKKYkyDpCZPj6APAtcuyVpIQQgjxICRIesJYuZUCIOtqHAaDYubaCCGEEMWXBElPGAcPP0Cd4RZzJd3MtRFCCCGKLwmSnjBaF7UlyYurHL2oN3NthBBCiOJLgqQnjbM6Jslbc5V/LqaauTJCCCFE8SVB0pPGWW1J8tZIS5IQQgjxICRIetLc1pJ07GIqiiKDt4UQQoiikCDpSePsC4CnRk9W2hUSr2WauUJCCCFE8SRB0pPGwR28qgDwom4r/8TJuCQhhBCiKCRIetJoNFBvAAA9dWs5Gpdi3voIIYQQxZQESU+i6l3ItHIiSHsJTq0zd22EEEKIYkmCpCeRrRNXK3YBoHP8JOKWfQrXk81cKSGEEKJ4kSDpCeXd4h30uhL4aZLwO/QtaX8MN3eVhBBCiGJFgqQnlKZEINaD9xPp0BeA3FMbQJYDEEIIIQpNgqQnmL2rB837fEqGYo2rIYWjh3abu0pCCCFEsSFB0hOudMkSxDrVBODvzcvNXBshhBCi+DB7kDR16lSCgoKws7OjTp06bN26tVDXbd++HSsrK2rVqmWS3qRJEzQaTb5X27ZtjeeMHj0633EfH5+HeVsWxbN6c/Vr0h6OXJB1k4QQQojCMGuQtGjRIoYMGcLIkSM5cOAADRs2pHXr1sTExNz1utTUVHr16kWzZs3yHVu6dCnx8fHG1z///INOp+Oll14yOa9q1aom5x05cuSh3pslKVFVfU6h2uMs2H3OvJURQgghigmzBkmTJk2iX79+9O/fn8qVKzN58mT8/f2ZNm3aXa97/fXX6dGjB2FhYfmOubu74+PjY3xFRUXh4OCQL0iysrIyOa9kyZIP9d4sSqna5Fo5UEKTRvY/v5Otv2TuGgkhhBAWz2xBUlZWFvv37yciIsIkPSIigh07dtzxutmzZ3P69GlGjRpVqHJmzpxJt27dcHR0NEmPjo6mVKlSBAUF0a1bN86cOXPXfDIzM9Hr9SavYkNnjSZADSi/UiZh9U0lWPUBZEjXmxBCCHEnZguSkpKSyM3Nxdvb2yTd29ubhISEAq+Jjo7mww8/ZP78+VhZWd2zjD179vDPP//Qv39/k/T69eszd+5c1qxZw4wZM0hISCA8PJzk5DsvuDhu3DhcXV2NL39//0LcpeXQNnyXWIcqXFA80SgG2P0j/BAKcX+rJ8jyAEIIIYQJsw/c1mg0Ju8VRcmXBpCbm0uPHj347LPPqFixYqHynjlzJtWqVaNevXom6a1bt6Zz585Ur16d5s2bs2LFCgDmzJlzx7xGjBhBamqq8RUbG1uoOliMwAZcfPEvns2cwgA+xuBeDq5dhNltYGZL+NwL1o81dy2FEEIIi2G2IMnT0xOdTpev1SgxMTFf6xLAtWvX2LdvH2+99RZWVlZYWVkxZswYDh06hJWVFRs2bDA5Pz09nYULF+ZrRSqIo6Mj1atXJzo6+o7n2Nra4uLiYvIqbp4JdMfbxZaojCqML/MjSoUIyLkBsbsgNwu2fQOXT5q7mkIIIYRFMFuQZGNjQ506dYiKijJJj4qKIjw8PN/5Li4uHDlyhIMHDxpfAwcOJDg4mIMHD1K/fn2T8xcvXkxmZiavvPLKPeuSmZnJ8ePH8fX1fbCbsnBarYaP2lQG4Kddl5niNQbafg3tvoHyzUHJhXU3x3plZ8DK9+HXPpCT9eCFKwos6Q8LX4bcnAfPTwghhHjE7j2w5xEaNmwYPXv2pG7duoSFhTF9+nRiYmIYOHAgoHZxxcXFMXfuXLRaLdWqVTO53svLCzs7u3zpoHa1dezYEQ8Pj3zHhg8fTvv27SlTpgyJiYl8/vnn6PV6Xn311UdzoxakQy0/rl7PYvSfx/hm/Rmc2jWj37NBENgQfqgPJ1bCiuEQfxAu7FUvqtYZKrd7sILP74Ajv6rfH10GNV66+/lCCCGEmZk1SOratSvJycmMGTOG+Ph4qlWrxsqVKwkICAAgPj7+nmsmFeTkyZNs27aNtWvXFnj8woULdO/enaSkJEqWLEloaCi7du0ylvuk690giGsZOXwddZKxfx1j+aGLnLp0jXl+LxISvwj2zjC94MjiBw+S/p576/tt30D1F6GAsWdCCCGEpdAoikxrKgq9Xo+rqyupqanFcnySoih8sfI4M7aeNaZpNQbWt9YTlLoHrifxj3sLqu14B0Vni+a9U2DnAud3QtQnUKkdhL0JOut7F3YjBb4OhpwM0FqDIRu6L4LgVrfOiV4Hp9ZB89FgbfcgNwZZ18HW6c7nJJ+G/bPh2WHg4F70soQQQhQ79/P5bfbZbcI8NBp1fNKEF2swrlN12lT3waBoeeNvfzJaTeJH3zG02+BJtMEPTW4ml/f+BmmXYXEvtRtu3Sj4sSFcPnHvwo78qgZIXlUh9A01bdukW8sOxO6Bhd1h9zS11epBrP8MvvSH6NvGuhkMsOFzOLFKfb/iXdjxHWz8vwcrSwghxBNNWpKKqLi3JP1XclomzSZtJiU9G43mVvwyxPp3hugWcwY/fH1KYZ+wF0oEQuY1SE8GOzd4fop68ukNanBStgm0/1ZtZcrNgWnhkHQCWo2Hqh1hcg3IzYTeK9W8pjeB64lqHlVfgJcib1VMUeCfJXDkN2j6EfjWuPNNJJ2CH+qpA9C9q8HrW0GrVes17wWwdoDef8GM59Tz7dzg3RMP1nIlhBCiWJGWJHHfPJxsmfhiTUo4WKMooNXAR20q0b3/u+SipSxx2CfsxaCzI/PFXxhfdg5HtcGQkaK2Li3uBfsjQR8HB+fDr73VWXH7Z6sBkr071OwGzj5Qq4da6ObxsOhlNUBy9FLTTm8EQ676ffoVWNANlvSDk6tg5fBbFc7Nhr/nmbYYrf9MDZAALv2jXgMQf0j9mp0O/+t66/yMFHWguhBCCFEAaUkqoietJSmPoigkX89Cq9Hg7mgDgD56B0t/m4dn+hn+MoRz0PFZEvQZ2JHJl7aRtHE6iY1bKfCpDiUrQ9SnakuRV1V1wcobV9WlBp65uWbVlTPwXR1QDOp7e3fovw6mN4XMVOi/AUoEwLyOkHAEdDZqi5IhG/quBStb+ONNNRDS6OCtvXA9CWZFgEYLldrC8T/Btxa8tkkNsv5ZYnqj3tXU68u3gFd+Mz2WmaZ2zV06AmFvgZPXo3zkQgghHqP7+fw26+w2YXk0Gg2eTrYmaS4Vwmk5qDZDFh5k99kroM/Aw9EGf3c3hsS+zlgrG37v3ABfVzt+3X+Bmk18qLL9HUg8qmbgVRVCegOQnWvg9zPW1PGKoOyl1SgaHbwUydTDCnU11ajPdji0AM5tg8vH1Ramnkth909wYB78NRSunFbHOIHacrTx/yDxuPq+Vg9o/hmcWq8uYxC7Ww20QO1uy05Xg7LOP8PUUDi9HtaMVGfblaqttjrNaX9rX7vsDGgz4dE+9EctO0N9XvZu5q6JKO4MBrULW4inhARJolB8Xe1Z9HoYpxLT2Hk6iZZVfbC30dFt+i6OXtQz8Jf9BHk68tfheMCaFoEziEicRc2cw8zM7sczBxPwc7NnUtQJ9p67ir+mJROsYlhrF8GlnU6sPHKC7rpK1LfefmsJAmdfePVP1l92YWF0KDOYZwy8lAot0dR7DeZ3vtVK5OABzceAowcEt1bTj/0BSTdXUm//rdoC1WAweFWGoMZwdjPs/F7dy67/elj7sRog2bmqX89tvfNDSb0AWyepgVnpuo/u4T+oX1+Fs1vhzV3gVsbctSk8RZFlIixJhh6mNYBStaDrPHPXRojHQrrbiuhJ7W67X3EpN2j/3TauXFdX5bbSqh9qOYY7/1o52VoRXs6Dv2NSSErLBNTPwuY+Gcy42heA63a+OL62kl0prvSatYesHAPfW0+hnW4X83KaM8NpIN90r0OdHW/eGlfUeSZHPVqw5p8EejvtxH3tO2Rq7bE13EBx8kYz/KTpX8KZaXByNeydCTE71KDsWjxZWLGsdiRdD9xcrf29M2rg9V8rhqsBndYa2nwFdfvc+UFdT4J/V4BXFbXFSveY/j5JvwITygIKdPgBat97BXqLcGghLBsI3ReaLhUhzOf0RrULXKOFEXFg43D/eRz9HS4egGajpEVKmI10t4nHxs/Nnu971KbnzD1oNfBDjxDKlnTiz0MXqejtTE1/Vxbvu8COU0lcTLlBgIcj4zpVJ9DTkfSsHH7YeIo1Ry8xtHlFWlfz4Z/vFmBIPsUbKUMou+wy+8+fJCvHQLNKXsT6T+bd6OOsumhPekoWXX/axeSmfWl3dgtUbMkGq2d5c9pObmTnsszGjq1asDXcAOBwjj8VsnJwsLntV97WSe1mC2oE3z8D1+IB+CWnOV/vt+ZFr2B0SSfg/Hao8rw6oHz9GHDxg/qvqes6gTpW6q8hYF9Cnb1XkBXD1FYtUIOxnsvU1qxH7dw24GbAGn8Yaj/6Ih+KQwsBRV2E9FEHSYoCF/9Wu4VlpuOdJd3c11ExwOV/wS/k/vNYORyuX4ayjaHccw+3fkI8AhIkiQcWXs6Tv95+FmudhvJezgAMbVHReHxYi4oMu+19HgcbK95rWYn3WlYyplUd/Ctj/jpG3PZzxEUnARBa1p0fXg7BzloHzSrzWWYOHyw5zIrD8by1Pgtd912kZhgYOe9vcg0K7o42xF535rBNEDW06mKZ29NKMWHuPub0qUd2rsK+81cIKVMCR1srdWB2y/+DP94kXbFlak4HrpPLKYdaBHOCayc28f7ffgRc+IMPM75FQUOmWznsrp4FrRXUehn+ngNbvoIqHfJ3EaVdRvl3BRpAsXNFcy0eFnRH6TKX5D2LsPMqj1P9XqDVPZwfiCFX/as/8Fm1OzFPwuGHk/+jZjBA3H71+3Nb1WUkHmXL2/E/YXFPCOkFz3/36Mq5X7k58HckVIiwjG7S29dEu/TP/QdJ15PVAAnU1iQJkkQxIEGSeCgq+z6cLkeNRsOn7apQ2ceFtMwcqpZyoW6gOzrtrcDDydaK77vXpqSTLZE7zvHO4n/IylVnynUOKc24TtX589BF0v5uAnFqkHRaG8T2U8l8/Ps/HLqQyvF4PQ42OhqU98TGSouLbXV8nIawPdlZDZrSMvntcgAjgQsH17EhsyEbbH8BDWhQuLLgdUoB+IdCi8/U8U+X/lGXJKgYYXpThxehMeRw0FCOf0Nn0u1AL7h6Fs1PDfG8eYpyaCaaTj+DVyUKFLsXDi+Eqp0gsMHdH+KeGbD6AzVgyxvQDuoAdoNBXabB2h4cPe+chzklR0OmXv0+U69+oPo/8+jKO7NR/Xr4V2j5Bdg6P7qy7sehBerCpwXNwDSHvJYkgEtH7//65Ohb3188+MDVEeJxkE5hYXE0Gg1dnvGn77NB1C/rYRIg3X7Ox20r07CCpzFAerNpOSa+VAMbKy2d65QmvGU34/kdWrUEYOHeWI7H69FpNaRn5RJ17BIrDsezYO8Fvkmqx35NFSL7PIO9tY7frwYCEEwMU90X4adJJlej/l1RCvUv4oslw9VutrzxSNsmqV8vn1SXOVj4Mum7ZgHwa25j5h5KQ98hknRFnUG4xxBMquKAJuEILHsNxWBg/u7zDJq/n2MX9eRmZZA4ozPMbA57fyZ9YR/mbY9ma/RlTiVeY9WReLafSjJ9OCdWqF+P/QFJJ1E0WnUZhaw0+Pcv+C4EJlZQZ/El/APA+eTrzN5+lg9+O0zkis0o+2bDhZutOTeuqrMLM/RF/Inep7yNlfOc2Uj0pWvsP3/VNP30RpgScqvbs6jib7aw5dxQx43dLjsDFr8Km80wwzHvOZzbBjmZ93dt5jW4dunh1sekJakIQdLtQVb8wQeujhCPg7QkiWLLSqfl++4hfB11gtpl3HihdmnTE/zqQsCzoNHQKDSMgakn+XHzaSp4OTGr9zNc0mdwJC4VDZB8PYvTl9N4tnxJqvm50rG2Hwv25HKWUgRpLtIsXV2YUtf2K5QN/4cmXQ1MPjrszdjwdPxD31QDiZid/PntYGqnbaZ09jlIPoUDkKFY82duGPp4PSN3O3E4axzB7jqcA2qz9e8jbLUfhm38IWbNn8fYo2oLz9qjlxjqsIo3c9aRrejIwgrHjEvsXRHJJ4ZwAHrrVlNOcxHXAdOoFuAFWekQs8vkMSQ5VaKks5067mbVB5CrDrLn7BayF/ZksPs0Vh9PRqfkMNX6WyJ0N4MjG2eSB+zFfcP7aI4vV5dH6DjVJO/sXAOL98VSyceZOgH32AcvLVFt5ar+IpQMvvN5F/apXx294HoiOac20HljTdKzctnwbhPKeDioC5X+NQSunoO1n0K5Zre6Oc9sBhtHdcZh1nXYNwuqdwFnb2MRO04noSjQoGwJ0w/8w4vURU/zRK+FY7+rXXL1B6r7Fz4uCbcFb3H7ISC88NfOe0FtRXxjh7rm2IO6cfXWqvigtkre7+zD24OklBh1UoHsnSgsnARJolhzdbBmTIdqBR/UWUGfWy0DH7QKpnU1Hyp6O2Nvo8Pf3YG6gQX/Jz2qfRVCy7rjaRgLB2aoC1j6VIeQV9FcOQs7pnAFVzbrvWk4YSNBno686fIqL16dQfurcwC4rLiSqLhRVXueVZpnqVq2DDvPJPPnoYuAD8Na1CKkTAmWHrjA4uyG9LRaR/mTP/OJlR9N7KKZkh5Br+xfQQNzPIfilJlIt7S5DHWK4rBVM6pf28Zo3VwA1q8eT7XXv1Zn6eVmke3gRdr1dEpo0tiYVYUuvk5qkHTtonqDHX8kd+3HWKecoeTl/6EoLZni+TsRafvJVTRk6Rywz7rGke+60UR7UL3m8CJ1axjXW8Ho538dY87O8wB0qunFpx1q4uZgk/+BZmeQOfclbBMPkrlvLrZvbic+x5ETCdcIL6d2eZKbrW5lczNIWlfiJZpf/wHNhb3kZKSRgx1rjyXQv2FZdQzY1XNq3olHuX5yI3Piy+CZvJ8uR15T18R69191iYbtk9Ug4+Z2N4nXMug1cw8GRWFTb1/K5Ny4tfHymU1qC0xeQJW335+Sq7boVGpjel9piWqrjUe5gn8Hiyo3Gy4du/X+7JbCB0lXz91qhTq6FJ4dqgYkNk5gVcDPpjAu3wxwHEuqeWWkgP4iuPrdOufMJjUtb0X9O+WR5+IBKN+saPW5m+wbavd3lQ6W03Uqii3pbhNPDY1GQ01/N+xt7j1A2s5aR4dafjiHvAj91sCry9XB3VodhA4C//pkN3yPuoEeaDVwNuk6w+ObMiG7CwAKGj7SvEM35XPetv4M6+e/oVfYrb/o/dzsaVPdF393B5pX9mZmbmsMiobGusP0s1pFuZxTfGszFWfNDXJ9a9P/zZF0e2M0WNkRlHWCTbU3853jz8b8no2fQ9alE2oXFLDPui7Ds19ne25Vvk1tSKLjbS03nhW5Wr4T3xteAuBd66UcqL+JNmlLAXgjewjvZL8FcCtAAjDkqBsFL+gBPzdn7bZdtwIk3VY+/7ctW398h9tXFck1KOTm5JDzx9vYJqp52aYnEDerJ20mb6b37L2EjltP5IotKN9UJfeHcAw3W3Y+OlWFBK0XOiWHsdazsCWLtccuqUs3bB6vFuDqD8CuBV/wzeqj1Dr0mZqena62/uStoXVyrfrhCaw8dJEvddOYaDWVbVtudtX5hagtj4qBzEO/ceyiXh0AH73m1v3njV3Kk5MJM5qp+wXG/qeL8HbXEkwDnsJIOqmuWp/n7F3W6/qvM7cN1j/2hxp0TqoMy167vzoASWmZ7D9/Rd1aCNSV6j1vTsK4vQVOfxHmd4Hf37hzXfNakpx91a8XD6hfryepLZxF6cIryKYv1fXQNhRiA+tLx9TFZG+kPJyyhTrh4Nw29esTQFqShLhfLr7Qby3ewK/NIDU9m4MXUohJvo6TXU1yHV5CZ2PH9MCGaG7rjsjMycXFzgp9Rg59GgRirVP/RnmnWQUGxKVy2PpZaqVtVRfFLN9CHagN6FqPV9eUcfSAmt3V/fC2TwZA8avL7os5hCoHubpoANaa62iAhcnlWG+owzmPRsRdvs73xy8z5mY9Nju3Y9zPu4lOCaeD3XICiYND09X8wt7m7NGmRCdeY6+mIs9oT5KDjtHZvfjcerY6mPim2rFdqaJ5nw7hNeh/eB667Eza6/9H9GJ3rL0qcOjfaA7GZ9BFu57KnCVH0TI2pycfWi3AL3kHb+a4Ml7XkyvXs7DeOQ2N1SV0aeo4mouKB+m2JZmQ0YmvrH+is24bFTRx9Dw3khtRy7G/fhncy6J0mYvmx2dpquxjnu14Kmribv2cNn6hDlIHyL6uBpCV2nB6/zrG6rYAcCL2PGhhs94Xz8BqVI3bx5kNs2jzVyCf10njlfTkW/md/k+QdHgxpMYAED+nN9+Wn8W4rvVu/cxzc2DXVLUeOTegy1wulopg6KKD1CrjxgctK6EtYLydmuHN/QZdSoP+AlzYowZ5Vnaw8GW1u6rvKrB1JvZKOl4uttha3Qz+b5/RePEALH8bcjJQjv9F5nU9do6F7zIcNP9v9py9wvbaB/EDzlAKVydnPC4fV7ftyZuksOWrW0HdvpkQ1NA0o+wMSFEDaqq/CDu+uzUuKepTdb/HC3thwAZ1kdakk0Wf/fbvX+rXEyug1bibu3Ur+WePGnLhtz7qcgZaHbQYky8ri3X1vLoUyeNab+1+bP0aNn2hroXVcJi5a/PApCVJiAfk6mBN44ol6RkWyAu1S6MLjoCgRiYBEoCtlY4JL9agd3ggr4TealWq5ufKzhHNqDVoLrQaDwO3Q6efYMBG6LMKytS/lUnz0ep/PtU6Q8VWaF6K5FDNT0lT7Chx5RCa5FMYFA1bcqrybHlPBjerAMCiWFeSFBdSFEcGH6/EvwnX8HB2QPfidKjSUZ3+3vZrNM1H0/UZf0DD59mvkG3lzLW6b3M5+GWOKoEAxNlVINGhPCU1Kfxh+ymvnR+GLjuNdKsSAFQ4/j2Bm9+hw6XvGaX9mcqcJVVxYHjuIJr2+phpLu8A0N9qFf803s/45u68qFM/2A8aygJgF/wcM3rV5XelEa9kf0S6lRs1tGeZbf0lNvt+BGC++yD2ZfixIbcWWo1CqEZtiZic01l9VjcDJMPN/+YOR83lQMxVql6+1QUbrI0FYEVSSXrt9iMHLZUNpyiruUjaoT8B2JBbi1xFo87OSr2gXmgwqB/0qK2GvjkXCP7na7afuhlU5eaomz5HfaIGSICy7A0mzPud3Wev8NPmM3y07AiG/y66mpujjre6OZh8WUYIqVYl1XFksbvV1pYTK+DSEZRDC5kUdZKGEzbSavJW/olLVeuV15LkcHMB1ES1FUtjyGbgF9+xaOqnGCaU49qJzZxKvEb2zYkP/3VJn8Ges1fURxmrPttZJ2yYd9ZJPWHbZPjlRdj+rbqeVZ7jf6qtZ7e7ckZdX8nWFSqokyiI+xuST6McWnjz/X61W3FWa3VM1ZlNanrMbkg6pX6/bzZ8U009ryBJpyD55rkpMZAUjX5mBzLGV0TRx5uee+RXNUACdWZj3sbaN51Nuk6nqduZv/t8wWWZyz9L4Nsa6rIVj3Mt6OyM/OXlZqvdzXkURe2WB3Wh3ieABYahQjy5WlXzpVU134IPOrhD6MBb7wtah8beLd9fZy0alKDTnjFMsPqRWtozHKY8DWtWYmTbyjjZWmFnrSUj24ZR3t8TWtad1E16fF3t+N+AUPw9HaHasyb5dQ4pzf/2xODj1QCrVwZTQqPhJ+DAscUM+uUXNmXVxc0ml89zv+U53UH1r36tFbo+fzI38ls6Zq3glOKHxq0MQc4G0pwCmaV5gecqV6BJsBehZUdwbq0DgXs/w3bH13S1+xk0Oew2VKKX4VOWtbWlSu0wwmwc+erFmqw95k1OeFOy57clBPUD8M/cUEb+U4q61/7lZPYgPiwTQ49KWqbtTWVyYj3a2h+lQrb6AfhjTjsGWS0nIGkzjaatY5vN7vyPvkwIyWdd2Zpbnaa6Q3xd9gAlLuwBYJPtc7hlpRGiOcX1hf3IvpaEjUcZHJJOoNg486X1IEZcH08fqzV8vTKSZwe/CyuGwokVKFZ2xIWOxubfZXgl7Wbw5dHstPmCrOwc3P/+ntlp9enzSm+0Oh2kxpEb2Y6sjBuk5FjjC2xLK4VBF0xn3WXOb11IQOlSxjrHR33HlGu+gIaAK9uwmz6I2IrP4Z+eBNaOHArsR81j6qy8TMUaW002TTQHee7SLrQaPXHz36RN1jisdDpCS9vzUl0/WtQqp65HBqw7fmt2nHPaGQBOKX7syXTmLaflWGXq4VSU+gIo9xxKVjqa2F3sWzaZur2+ZMvJy4xYeoTW2t18DKS7lsOhVC11zJg+Dn5ujka5LThZ+PKt5R8OL1bPm9VSXY+s+ktw6H/qsb0z1UVg/+vkKpO3N1Z9jEucGlBFr5lGheZ9YV4ncPZRg6g81y6qgVe5psakHzed5u+YFP6OSSElPZs3m5Y3LeviQfXfrFsZLp39h8srx+HbdgQegXcYI3kX8ak36DZ9F02DvRj9fNU7n5ihh9Uj1O9PrFS3Uwp9477LK1BqHBxfDnX6GBdVNRgUft52hobZu6i8/R31/6eIz9Xz9RdhViu1a7v/enWCwOV/1b01QQ2Cs66r+aYn3d/EAwsi25IUkWxLIizJphOJxCVfo372HkpXDcPOM9B47H+7Y9h1JpkxHari5mDD+eTreDjZ4mR7/38jvfLzbrbdXHIg0N2e9R2y0e2eqq7fVOdVzlxOY9U/CbSvUUqdhXY3e2ZA1Ci1KwzY/ewsnKo0p2op1wJPv7B1PqXXDyJVcaCv01T2J98ahPy//vUJL+/Jr/tiee+3w/TWrWa09VxScWJanb8YfLgTDtlX2JJbnUa6I1yz98O5wrNweBGK1hrNR3FsOaMndvMcXo4ba8w329qF9EEHWTTlfV5T8q9V9E/Aq7Q70ZJRNr/QR7sSvWLPDbeKeKcewoCWdwzD+DMrBHf0LLf9mNKaJBK9G2J7IxFXvTrO57K1H4e82lMufhVBBtNWi5+qzOPK5YuMuPwBmVijcfTE5vqtFpHuWR/TvmlDOux8EUfDrb/oE30a8/z5LmyyGYKiteZo5Xeoe2wcBq01WkO28byZhvY0Zj/lteqA/nXaMOJb/EjXuv4Mm7OBv05l0UG7jW9tppKjaHkmcypXcaFb7ZJ82UDHjVObyD60FOv0BKx6LWXXrm00PPIRVxUn1tX+ni8OO3I1PZu3dUt51/o3fsttxLF64xkRdArrpX3VwfLAqOxX+cx6junDtXVVu+3yus9uo9i5cmXQcTxcHAGISU5Hp9Pg9/tL6gKk7uVufVjflKDxwqtyA7THlt1KdPRSu/UOL+RGxQ4cta2N741/8dZeY9S/ZZifdavb8I0m5Xi/ZbDaQpx8Wh2L5uBB6oDdnJ7yPCG5h4mxq0iZ93eRlq2QkZ1ruln4lbPqPpE1uoJ/PTUtNxvSr/Dlxjh+3BGPlVbD3pHNKeH4nwH2f89Vl2BIu6S2gFk7QvZ1DFobrnach3v1lrdarhP/VQes3z6o/jb6jGy2RScRZKOn8o5hUKEFPDsEItvBua2cKNeHSMe+fNKuCuuOJ/LVwtWstP0IZ9QWUV79E/zqwOzWt7qFyzZVdxHYOlEdt5in+yJY/pa6iOjLv6llWYD7+fyWIKmIJEgST6O9567w0o87ARjboSo9wwIfLMO0y7DnJ3XKfoMh95xSvmXDShxcS+JbrhpNJ24iK8eAr6sd2z94Dq1WQ3pWDi/8sAOy0pjhuYDSz3RAW+NFWD9W/Q/8pozw97Cr2Ql+bqauTP7yr+qBrOvwVQU1cLNzhZeXgP8zLN+0kwobXuMCXhxyaYpbyj94aPR8lt2LFJx5+ZlSDDj9NoHpRwDIVKz4OKcvv+Y2wcXOiqqlXKlpdZb3LgxGZ1CXYMi0cSMzMxMXzQ1jvRIVN3J09pQyxGPQ2aL9KI4sg5ZT48KoYlCDqhuKDTtswmmWvYk0j2o42TvAhT0k4ImXkoxWo/B/uT2Zkd2awdUyGRJRDa2T5609/IAMJ3/s0mILfMYdMsfQy+M4ndMWsNtQiRq689grN/gmuzM/67pwPUsdW/dO84qMW3ncuE9jeDkPjl9IYp4ykmrac2Qq1nyQPYAzXi2YZzUG16QDfJndjR9znye0rDs/h13B/o8BRGVWYWD2UH6zGU1d7UliPJ7FNfVfXHNurf91PWQg2kPzOe/XjrIJq7DJSuHFrNG8/YwDZVP3su30Fa4pdvSzWoUOA2NdP+OT1FEA5CoabmjscOLWc44v343sM9v5y7MfNq4+9I8eyH/lKhqG2H9O9fDWfLFSbZXsFRbAx22rYLPvJ1j9IQD77BtQ98Z243VXm03ko51w41oqHw4aQCVfV8hMwzCjKdqkk2pQHv622nIVp87kvIgnL2SMpo72JN/az0Bx8eeAdW12B/Snsn0qLba8aFK3Y01+5sq2GTybo7aKLtVG4PLCJBp7XEU34zmydfZENVhIrWqVKJ16AMqEgY0jU9ZH892GaLJzDcyz/YqGmoOg0cELP8HS/gCkKXaEZ05hQIsQjh87zMDLY6mhPUuuzhZdbqY6FsrGCZJOoNi7Q3Y6mpwMaDtJDebiD4KNM2RdA48KtxYRdfGDQbvUcXUnV6sTIWp0hTKhBf4ePkoSJD0GEiSJp9Xo5Uc5n3ydqS/XKdRMwUfl67Un+G7DKYY2r8g7zSvc/WRDrjqWY8tX6kym1zaqSxlcT1L/w799z7Ztk9Wp889/D741jMn7z1+ldAl7vF3sOJ98nSnrT7H0wAV0Gg0rBjfEJTeZM5EDSdD5csT/FcqXK88zge5U8HK6NUD74P/UGWBOPtD7L1ac13Bm4zw6GtbiQSpZL87Fzc0dFvVSg7fWXwJwdONiqm4eAECUJoyQnl/gMfc5jPvyWdmz6tnFLFi7jWbav/kqpytNapTj2261by3G+lPjm4OlNfDmHpj/ojqYuvLz0HYSuWs/QXd4AUeVsgRzDivNrbFKuwyV6ZE1kvdaVWHmtjMkpWUZjwV4OJCoz+RGttptFlbahg/SJ1ErfQcAmR6VsU0+DtYO7Gi2lNdW6UnLzKGMuwO+jrA79jq1/Etw/cI/dNdtYFrO8wy0+pN+VmrX2bWSdWh6dcTNzbA1xo2uV+bWI0K7z6SeACcMpWmZNZ5ttu9QWpPEvyWakuvkQ9VYddLBEbdmdL48wLgILSistXmfito44inJkpxwKmtiaKY7gN7WB5fBO5j/Txpjfj+ATsmlpIc7s6y/olzKdpNyL2vcKalcIRctOtS891jXo0K7ocRv/IkqKZvIVnRYa0zHPuWJNvhRRnMJW82tWWEbcmuRjRUtdfvAMxgUA2dd6tL0eHscyOBT2wV006jdnTNzWlPZOoFw5YDxOWg1UEFzAYNHBa40ncDIBVtwIw0fzVWGWt3WMqrRqctc3DQrpxVu2hs8r9mKlcZAiuLI7OBpDEn4CI1eHZen2DgxWPsRZTOPMVT55bY70cBzI01blNRNmcAtQP33l5l688lr2OHVjcqdR+Lu7U9CagZJaZn4uzvgam9d4HN6GCRIegwkSBLCvBRF4Z84PVVKuRS4KvtdLry/RRDv4szlNDKyDVQpdR//B1w6Bi6l1PFlhaUoxI6vj3/GCf5tMoNKTbqoA5vPbIKkaKjZndzgtrSdspV/E67RvLIX016pY5xBCaibM2/9Wu1e6rlMXQ/qyhn1L3mNRl3H6Id65AVeUbkhlPAJJMQllRcudOdMpgsb3m3CN+tO8r/d6nie3uGBjGpfhSNxqfSN3MeNrByWDmpAKVcbjv7yPqFxkWrZGh30WAQVWvBvgp5+kfuIS7nVsrNycENGLz/KnnNXcLDRUTH7BL/bfgrAOzlv80dOGBW9nXC2s6bKpeWMZZrx2j2GYJK9wmlYxobExEuc83+BLL9QShybQ6Vzv2DfcwEoCjbTnyVH0dIi6yvOKr60qupD3cASxKXcILxkJmEuSViXa0Tn6Xs5G3eJFbYfEai5BBotuPhh0F8kS9HRI/Mj5tmMw1GTyWXFlZKaVBQ0rGm8jLIb36SiNo5MxRoNBmxuC4hyFC19lE+pkXuMDrrtxPm1onGXofT6eRvfpr2Hh0btLl2TW5e/ckOZaPMTtqjdkQY0aAbtJMm+LC2+2UxKejadQvwY1b4q9qf+wmZJb2M52VhxQ+eMS+5/VqgvwAb7CJreiEJz82f+Y047BlqZdm/u1oUwOv0lLjlU4EWfS9SImUeWfwOOuTfj530p6MhlmudvNE9fhdaQRYL7M2ifn4xXpLp9UraiI6H5t/ivf8uYZ6rOnROaIOrlqAvX5qIlp2QVYhJTOW3w4ducTrgF1ub/2vhT1t1endn7EEmQ9BhIkCSEeJyUtERyE45iVb7pHc+JvZLO9lNJdKztZxyAbZSRCju+V2cyuvkXnMGiV+D4n+RaOzG16gJ6NK+Ph5MtyWmZZOcq+Lja8U9cKp2n7aBdjVJ89WINYytZRnYu1zNz8Lh9HM7hX2HHt2pXavVbXUb6jGy+XnOCubvO07hiSSL71CMhNYNlB+LoUKsU41Yep83x93HiBn2z36dNrTJ82amG2nKpj4dJ6h6HuVobfg1dykvNn71noJx7bDnbz6Uz5l9fGpTz4JN2VbC6PYi86XzydfpE7qWzbxJvJv2fGkjeJs2mJE5Zl0m3diem0SSCN/RDU6s7N1pPof0Xi6mWdZiMgOfoFGyNbv1o/DRJ5Ni4oAl9g0rPvULUsUsM/GU/bg7WfPZ8Vd5ZeJDGttFE2k3iUG4AXdOGkYkNS0MOEXJMXQ/sr9xQPPv8jzk7zrHqnwSq+Lrwx1sNbgXBK99Xu62BnGdew6r6iyi/vkqCc3VeOduC960W8ZzuAKcNpSjhE4BH1kXWJJfk7ey3meU2myYZ69meW5Ve2R+y120k7hkx/G0oz5jsXnzQ/xUGzd/P1fRsCmKt05Cdq+BJKk11B9ipVCeobEUmxnbFW5PCn7mhfGY7nOnPprP573+IuuzGCcWfXHS0tT3EAOU3amlNx48ZFA03sMFRk8lh745UHxiZb7bwg5Ag6TGQIEkI8cRJPq0uxFh/IFTteMfTcnINBQYY9yslPQt7G92tNZ5uStRnEDF5C2kZOYxsW5ne4YGmH5LTnlXXaWr0vtq18yjp4+HqWdDZwuxWt7b1qd4FOs+A68nq+DWdFf/bHcOv+2P5pkstAjwcmL87BiuthhfrlDY+r1yDQsPxG7iYmoGDjY70rFzealqe4c8FMH3HBb5YdYI6ASX49bX6aH97lRsnNtLuxihitKXJzlXQaTX88WYDqvndNsEhOwPmPg/X4mHAJrXl5WaL6buLD7Hk7wtoMOBib8vuj5phZ60zTsJw4Tr9bdZCze4ElKtE+yAtmqun+eakJwoahrWoyIilR1i4Vx3D9mKd0vy2X+1ye6lOaSp4OxnHbHm72HJJr66XNdTqVwbZrWWo/Rf8dbmksaoudlYMa1ERB1srnqvkxY+bTrNu+w7Kay5ibWPHpIr/YH/yD+P5h5ybUPPdW+8fyo9UgqRHT4IkIYR4dBL1GeQYFEq52ec/GH9IHfhc7zV1y6DHZfUIdYFQgI7T7rwFyz18E3WSb9erA5odbHRs++A53B1tyM418OehizxXyUvd3kdROHVJT/PJ2wBwtbfm03ZV6FyndP5M8z7K/9PikqjPoOnETVzPyqV3eKBxiYGlf19g2OJDWOs0/PzqMzSuWPK/ORodj9fTf84+eoYFMLBxOVYcjmfXmWSGtwzGydaKHzefpqSzLRFVvGk5eQuX9JnUKO3KH4PCuZFj4P9WHGf+7hjsrLXM71/fZJ/HtMwcIiZt5mJqBtNeDqF1dV9IiUXJzWJtjIZnKpbG/b+z/R6QBEmPgQRJQgjxlLmeBFNC1NXF3zmkrrdUBBeuptNwwkYUBV5vVJYRbSrf9fxlBy6QkJpJj/plijSg+a/DF1m4J5avXqqBr6sadObkGvhpyxlCypQgrNzDG/Oz79wVJq49wYetK1PL382YfuRCKk52VgR5Oua7Jj71Bpf0mSbnP0oSJD0GEiQJIcRTKPm0ukWMz/0vGnm7z/48yr5zV4ns84zpOC7xyN3P57esuC2EEEIUlke5h5LNqPZ3WVlbWAzZu00IIYQQogASJAkhhBBCFECCJCGEEEKIApg9SJo6dSpBQUHY2dlRp04dtm7dWqjrtm/fjpWVFbVq1TJJj4xUF5367ysjI+OhlCuEEEKIp4NZg6RFixYxZMgQRo4cyYEDB2jYsCGtW7cmJibmrtelpqbSq1cvmjVrVuBxFxcX4uPjTV52drf2ZipquUIIIYR4eph1CYD69esTEhLCtGm39uGpXLkyHTt2ZNy4cXe8rlu3blSoUAGdTsfvv//OwYMHjcciIyMZMmQIKSkpD73c28kSAEIIIUTxcz+f32ZrScrKymL//v1ERESYpEdERLBjx447Xjd79mxOnz7NqFGj7nhOWloaAQEBlC5dmnbt2nHgwIEHLjczMxO9Xm/yEkIIIcSTy2xBUlJSErm5uXh7e5uke3t7k5CQUOA10dHRfPjhh8yfPx8rq4KXeKpUqRKRkZEsX76cBQsWYGdnR4MGDYiOji5yuQDjxo3D1dXV+PL3v8MGkUIIIYR4Iph94PZ/d/ZVFKXA3X5zc3Pp0aMHn332GRUrVrxjfqGhobzyyivUrFmThg0bsnjxYipWrMh3331XpHLzjBgxgtTUVOMrNja2MLcnhBBCiGLKbCtue3p6otPp8rXeJCYm5mvlAbh27Rr79u3jwIEDvPXWWwAYDAYURcHKyoq1a9fy3HPP5btOq9XyzDPPGFuS7rfcPLa2ttjaytLxQgghxNPCbC1JNjY21KlTh6ioKJP0qKgowsPD853v4uLCkSNHOHjwoPE1cOBAgoODOXjwIPXr1y+wHEVROHjwIL6+vkUqVwghhBBPJ7Pu3TZs2DB69uxJ3bp1CQsLY/r06cTExDBw4EBA7eKKi4tj7ty5aLVaqlUz3VDQy8sLOzs7k/TPPvuM0NBQKlSogF6vZ8qUKRw8eJAffvih0OUKIYQQQpg1SOratSvJycmMGTOG+Ph4qlWrxsqVKwkICAAgPj7+vtcuSklJ4bXXXiMhIQFXV1dq167Nli1bqFevXqHLFUIIIYQw6zpJxZmskySEEEIUP/fz+W3WlqTiLC+2lPWShBBCiOIj73O7MG1EEiQV0bVr1wBkvSQhhBCiGLp27Rqurq53PUe624rIYDBw8eJFnJ2d77q+UlHo9Xr8/f2JjY2VrrxHSJ7z4yPP+vGQ5/z4yLN+PB7Fc1YUhWvXrlGqVCm02rtP8peWpCLSarWULl36kZbh4uIi//geA3nOj48868dDnvPjI8/68XjYz/leLUh5zL7ithBCCCGEJZIgSQghhBCiABIkWSBbW1tGjRol26A8YvKcHx951o+HPOfHR57142Hu5ywDt4UQQgghCiAtSUIIIYQQBZAgSQghhBCiABIkCSGEEEIUQIIkIYQQQogCSJBkYaZOnUpQUBB2dnbUqVOHrVu3mrtKxdro0aPRaDQmLx8fH+NxRVEYPXo0pUqVwt7eniZNmnD06FEz1rj42LJlC+3bt6dUqVJoNBp+//13k+OFebaZmZm8/fbbeHp64ujoyPPPP8+FCxce410UD/d61r179873ex4aGmpyjjzrexs3bhzPPPMMzs7OeHl50bFjR06cOGFyjvxeP7jCPGdL+Z2WIMmCLFq0iCFDhjBy5EgOHDhAw4YNad26NTExMeauWrFWtWpV4uPjja8jR44Yj02YMIFJkybx/fffs3fvXnx8fGjRooVxbz5xZ9evX6dmzZp8//33BR4vzLMdMmQIy5YtY+HChWzbto20tDTatWtHbm7u47qNYuFezxqgVatWJr/nK1euNDkuz/reNm/ezJtvvsmuXbuIiooiJyeHiIgIrl+/bjxHfq8fXGGeM1jI77QiLEa9evWUgQMHmqRVqlRJ+fDDD81Uo+Jv1KhRSs2aNQs8ZjAYFB8fH+XLL780pmVkZCiurq7Kjz/++Jhq+GQAlGXLlhnfF+bZpqSkKNbW1srChQuN58TFxSlarVZZvXr1Y6t7cfPfZ60oivLqq68qHTp0uOM18qyLJjExUQGUzZs3K4oiv9ePyn+fs6JYzu+0tCRZiKysLPbv30/E/7d3dyFNvn0cwL/T5phDRPNlM8mkv1a+JKQhmhUpiAsD08jEYnaQaCpFdhK9aB11UNZJCIZJkSAIFpKUaGqQIklqWloIvhTkME1Ks7Ty9z/oecazx1nm26Z8P3DDveu6N3/3l+vg53aNxcaajcfGxqKpqclKVa0OPT098PLygq+vLw4dOoTe3l4AQF9fH4xGo1nmKpUKu3fvZuYLNJdsnz9/ju/fv5td4+XlhaCgIOY/Dw0NDfDw8IC/vz+OHTuGoaEh0xyznp9Pnz4BAFxdXQFwXS+V/8/5v2xhTbNJshHDw8P4+fMnPD09zcY9PT1hNBqtVNXKFx4ejjt37qC6uho3b96E0WhEZGQkRkZGTLky88U3l2yNRiMcHBzg4uIy6zU0N3q9HqWlpairq8PVq1fR0tKC6OhoTE5OAmDW8yEiOHXqFKKiohAUFASA63opWMoZsJ01vWbRXokWhUKhMHssIjPGaO70er3pPDg4GBEREdi4cSNu375t2gTIzJfOfLJl/n8vOTnZdB4UFISwsDD4+PigqqoKiYmJsz6PWc8uOzsbHR0dePr06Yw5ruvFM1vOtrKm+U6SjXBzc4O9vf2MDnhoaGjGfy00fxqNBsHBwejp6TF9y42ZL765ZKvVajE1NYXR0dFZr6H50el08PHxQU9PDwBm/bdycnJQWVmJ+vp6eHt7m8a5rhfXbDlbYq01zSbJRjg4OCA0NBQ1NTVm4zU1NYiMjLRSVavP5OQkuru7odPp4OvrC61Wa5b51NQUnjx5wswXaC7ZhoaGQqlUml0zODiIly9fMv8FGhkZwbt376DT6QAw67kSEWRnZ6OiogJ1dXXw9fU1m+e6Xhx/ytkSq63pRdsCTgtWVlYmSqVSiouLpaurS06ePCkajUb6+/utXdqKlZubKw0NDdLb2yvNzc0SHx8vTk5OpkwvX74szs7OUlFRIZ2dnZKSkiI6nU4+f/5s5cpt39jYmLS1tUlbW5sAkIKCAmlra5OBgQERmVu2GRkZ4u3tLbW1tdLa2irR0dESEhIiP378sNZt2aTfZT02Nia5ubnS1NQkfX19Ul9fLxEREbJu3Tpm/ZcyMzPF2dlZGhoaZHBw0HRMTEyYruG6Xrg/5WxLa5pNko25ceOG+Pj4iIODg2zbts3sK5H095KTk0Wn04lSqRQvLy9JTEyUV69emeanp6clLy9PtFqtqFQq2bVrl3R2dlqx4pWjvr5eAMw4DAaDiMwt269fv0p2dra4urqKWq2W+Ph4efv2rRXuxrb9LuuJiQmJjY0Vd3d3USqVsn79ejEYDDNyZNZ/ZiljAFJSUmK6hut64f6Usy2tacV/CiYiIiKi/8E9SUREREQWsEkiIiIisoBNEhEREZEFbJKIiIiILGCTRERERGQBmyQiIiIiC9gkEREREVnAJomIaAEUCgXu379v7TKIaAmwSSKiFSstLQ0KhWLGERcXZ+3SiGgVWGPtAoiIFiIuLg4lJSVmYyqVykrVENFqwneSiGhFU6lU0Gq1ZoeLiwuAXx+FFRYWQq/XQ61Ww9fXF+Xl5WbP7+zsRHR0NNRqNdauXYv09HSMj4+bXXPr1i0EBgZCpVJBp9MhOzvbbH54eBj79++Ho6Mj/Pz8UFlZaZobHR1Famoq3N3doVar4efnN6OpIyLbxCaJiFa18+fPIykpCS9evMDhw4eRkpKC7u5uAMDExATi4uLg4uKClpYWlJeXo7a21qwJKiwsRFZWFtLT09HZ2YnKykr8888/Zn/j4sWLOHjwIDo6OrB3716kpqbi48ePpr/f1dWFhw8foru7G4WFhXBzc1u+AIho/hb153KJiJaRwWAQe3t70Wg0ZselS5dE5NevjWdkZJg9Jzw8XDIzM0VEpKioSFxcXGR8fNw0X1VVJXZ2dmI0GkVExMvLS86ePTtrDQDk3Llzpsfj4+OiUCjk4cOHIiKyb98+OXr06OLcMBEtK+5JIqIVbc+ePSgsLDQbc3V1NZ1HRESYzUVERKC9vR0A0N3djZCQEGg0GtP8jh07MD09jTdv3kChUOD9+/eIiYn5bQ1bt241nWs0Gjg5OWFoaAgAkJmZiaSkJLS2tiI2NhYJCQmIjIyc170S0fJik0REK5pGo5nx8defKBQKAICImM4tXaNWq+f0ekqlcsZzp6enAQB6vR4DAwOoqqpCbW0tYmJikJWVhStXrvxVzUS0/LgniYhWtebm5hmPN2/eDAAICAhAe3s7vnz5YppvbGyEnZ0d/P394eTkhA0bNuDx48cLqsHd3R1paWm4e/curl+/jqKiogW9HhEtD76TREQr2uTkJIxGo9nYmjVrTJujy8vLERYWhqioKJSWluLZs2coLi4GAKSmpiIvLw8GgwH5+fn48OEDcnJycOTIEXh6egIA8vPzkZGRAQ8PD+j1eoyNjaGxsRE5OTlzqu/ChQsIDQ1FYGAgJicn8eDBA2zZsmUREyCipcImiYhWtEePHkGn05mNbdq0Ca9fvwbw65tnZWVlOH78OLRaLUpLSxEQEAAAcHR0RHV1NU6cOIHt27fD0dERSUlJKCgoML2WwWDAt2/fcO3aNZw+fRpubm44cODAnOtzcHDAmTNn0N/fD7VajZ07d6KsrGwR7pyIlppCRMTaRRARLQWFQoF79+4hISHB2qUQ0QrEPUlEREREFrBJIiIiIrKAe5KIaNXibgIiWgi+k0RERERkAZskIiIiIgvYJBERERFZwCaJiIiIyAI2SUREREQWsEkiIiIisoBNEhEREZEFbJKIiIiILGCTRERERGTBv6dk44hMfZ3aAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 1s 5ms/step - loss: 0.4564 - accuracy: 0.8170\n",
      "Loss:  0.456437885761261  Accuracy:  0.8170375227928162\n"
     ]
    }
   ],
   "source": [
    "class ANNModel:\n",
    "\n",
    "    # Hyperparameters\n",
    "    def input_layer(self):\n",
    "        return keras.layers.InputLayer(input_shape = (69,)); # 11 is total features dimension\n",
    "\n",
    "    def hidden_layer(self):\n",
    "        return [\n",
    "            keras.layers.Dense(256, kernel_initializer = \"glorot_uniform\", kernel_regularizer = tensorflow.keras.regularizers.l2(1e-4)),\n",
    "            keras.layers.Activation(\"sigmoid\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            \n",
    "            keras.layers.Dense(256, kernel_initializer = \"glorot_uniform\", kernel_regularizer = tensorflow.keras.regularizers.l2(1e-4)),\n",
    "            keras.layers.Activation(\"sigmoid\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            \n",
    "            keras.layers.Dense(128, kernel_initializer = \"glorot_uniform\", kernel_regularizer = tensorflow.keras.regularizers.l2(1e-4)),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dropout(0.5),\n",
    "        ];\n",
    "\n",
    "    def shallow_hidden_layer(self):\n",
    "        return [\n",
    "            keras.layers.Dense(64, kernel_initializer = \"glorot_uniform\", kernel_regularizer = tensorflow.keras.regularizers.l2(1e-4)),\n",
    "            keras.layers.Activation(\"sigmoid\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(64, kernel_initializer = \"glorot_uniform\", kernel_regularizer = tensorflow.keras.regularizers.l2(1e-4)),\n",
    "            keras.layers.Activation(\"sigmoid\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dropout(0.5),\n",
    "            keras.layers.Dense(32, kernel_initializer = \"glorot_uniform\", kernel_regularizer = tensorflow.keras.regularizers.l2(1e-4)),\n",
    "            keras.layers.Activation(\"sigmoid\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dropout(0.5),\n",
    "        ];\n",
    "\n",
    "    def output_layer(self):\n",
    "        return keras.layers.Dense(1, kernel_initializer = \"glorot_uniform\", activation = \"sigmoid\"); # Since output is only 1 label.\n",
    "\n",
    "    def optimizer(self):\n",
    "        return keras.optimizers.Adam(learning_rate = 1e-3);\n",
    "\n",
    "    def loss(self):\n",
    "        return \"binary_crossentropy\";\n",
    "\n",
    "    def metrics(self):\n",
    "        return \"accuracy\";\n",
    "\n",
    "    def epoch(self):\n",
    "        return 1;\n",
    "\n",
    "        \n",
    "    # Callbacks\n",
    "    # Backup Model to h5 file\n",
    "    def _callback_model_backup(self):\n",
    "        checkpoint_path = current_folder + \"/cua/\" + \"model_checkpoint.h5\";\n",
    "\n",
    "        return tensorflow.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_path,\n",
    "            save_weights_only=True,\n",
    "            save_freq='epoch'\n",
    "        );\n",
    "\n",
    "    # Early stopping after loss are not improved for some epochs\n",
    "    def _callback_early_stopping(self):\n",
    "        early_stopping_tolerance = 50;\n",
    "\n",
    "        return tensorflow.keras.callbacks.EarlyStopping(\n",
    "            monitor = \"val_loss\",\n",
    "            patience = early_stopping_tolerance,\n",
    "            restore_best_weights = True\n",
    "        );\n",
    "\n",
    "    # Fitting\n",
    "    def fit(self):\n",
    "\n",
    "        # Construct the model \n",
    "        model = Sequential();\n",
    "        model.add(self.input_layer());\n",
    "\n",
    "        for i in [self.hidden_layer(), self.shallow_hidden_layer()]:\n",
    "            for j in i:\n",
    "                model.add(j);\n",
    "                print(model.output_shape)\n",
    "\n",
    "        model.add(self.output_layer());\n",
    "\n",
    "        # Draw the model architecture\n",
    "        plot_model(model, to_file=(current_folder + \"/cua/\" + \"model_architecture.png\"), show_shapes=True)\n",
    "        model.summary()\n",
    "\n",
    "        # Compile the model pipeline\n",
    "        model.compile(loss = self.loss(), optimizer = self.optimizer(), metrics=[self.metrics()]);\n",
    "\n",
    "        telegram_reporter(\"Starting training model with code [202401200128] with total epoch of \" + str(self.epoch()));\n",
    "\n",
    "        # Fitting\n",
    "        model_plot = model.fit(\n",
    "            feature_train_scaled, \n",
    "            label_train, \n",
    "            epochs = self.epoch(), \n",
    "            validation_data = (feature_validation_scaled, label_validation), \n",
    "            callbacks = [self._callback_model_backup(), self._callback_early_stopping()] \n",
    "        );\n",
    "\n",
    "        plt.plot(model_plot.history[\"loss\"], label = \"Model Training Loss\");\n",
    "        plt.plot(model_plot.history[\"val_loss\"], label = \"Model Validation Loss\");\n",
    "        plt.title(\"Training and Validation Loss\");\n",
    "        plt.xlabel(\"Epochs\");\n",
    "        plt.ylabel(\"Loss\");\n",
    "        plt.legend();\n",
    "        plt.show();\n",
    "\n",
    "        return model;\n",
    "\n",
    "dojo = ANNModel();\n",
    "model = dojo.fit();\n",
    "\n",
    "loss, accuracy = model.evaluate(feature_test_scaled, label_test);\n",
    "print(\"Loss: \", loss, \" Accuracy: \", accuracy);\n",
    "\n",
    "telegram_reporter(\"Finished training with Loss: \" + str(loss) + \" Accuracy: \" + str(accuracy));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
