{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow;\n",
    "import pandas;\n",
    "from sklearn.model_selection import train_test_split;\n",
    "from tensorflow import keras;\n",
    "from tensorflow.keras.models import Sequential;\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt;\n",
    "from tensorflow.keras.utils import plot_model;\n",
    "import requests;\n",
    "import time;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorflow.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0      20000    2          2         1   24      2      2     -1     -1   \n",
       "1     120000    2          2         2   26     -1      2      0      0   \n",
       "2      90000    2          2         2   34      0      0      0      0   \n",
       "3      50000    2          2         1   37      0      0      0      0   \n",
       "4      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0     -2  ...          0          0          0         0       689         0   \n",
       "1      0  ...       3272       3455       3261         0      1000      1000   \n",
       "2      0  ...      14331      14948      15549      1518      1500      1000   \n",
       "3      0  ...      28314      28959      29547      2000      2019      1200   \n",
       "4      0  ...      20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  LABEL  \n",
       "0         0         0         0      1  \n",
       "1      1000         0      2000      1  \n",
       "2      1000      1000      5000      0  \n",
       "3      1100      1069      1000      0  \n",
       "4      9000       689       679      0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading data from pre-cleaned csv file\n",
    "current_folder = \"/mnt/d/Code/College/Machine Learning/Team Assignment/Default Credit Scoring/\";\n",
    "# current_folder = \"\";\n",
    "dataframe = pandas.read_csv(current_folder + \"credit_card_clients.csv\");\n",
    "\n",
    "dataframe = dataframe.drop(columns = [\"ID\"]);\n",
    "\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance based on LightGBM\n",
    "\n",
    "This time, we gotta use the top 10 the most important features according to LightGBM\n",
    "\n",
    "PAY_0\n",
    "PAY_2\n",
    "PAY_AMT2\n",
    "LIMIT_BAL\n",
    "PAY_AMT3\n",
    "BILL_AMT1\n",
    "PAY_3\n",
    "PAY_4\n",
    "PAY_6\n",
    "PAY_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping everything that other than mentioned above\n",
      "Dropping feature SEX since its not \"important\"\n",
      "Dropping feature EDUCATION since its not \"important\"\n",
      "Dropping feature MARRIAGE since its not \"important\"\n",
      "Dropping feature AGE since its not \"important\"\n",
      "Dropping feature BILL_AMT2 since its not \"important\"\n",
      "Dropping feature BILL_AMT3 since its not \"important\"\n",
      "Dropping feature BILL_AMT4 since its not \"important\"\n",
      "Dropping feature BILL_AMT5 since its not \"important\"\n",
      "Dropping feature BILL_AMT6 since its not \"important\"\n",
      "Dropping feature PAY_AMT1 since its not \"important\"\n",
      "Dropping feature PAY_AMT4 since its not \"important\"\n",
      "Dropping feature PAY_AMT5 since its not \"important\"\n",
      "Dropping feature PAY_AMT6 since its not \"important\"\n"
     ]
    }
   ],
   "source": [
    "print(\"Dropping everything that other than mentioned above\");\n",
    "\n",
    "most_important_features = [\n",
    "    \"PAY_0\",\n",
    "    \"PAY_2\",\n",
    "    \"PAY_AMT2\",\n",
    "    \"LIMIT_BAL\",\n",
    "    \"PAY_AMT3\",\n",
    "    \"BILL_AMT1\",\n",
    "    \"PAY_3\",\n",
    "    \"PAY_4\",\n",
    "    \"PAY_6\",\n",
    "    \"PAY_5\",\n",
    "    \"LABEL\" # Don't :)\n",
    "];\n",
    "\n",
    "columns_to_be_dropped = [];\n",
    "for i in dataframe.columns:\n",
    "    if i not in most_important_features:\n",
    "        columns_to_be_dropped.append(i);\n",
    "        print(f\"Dropping feature {i} since its not \\\"important\\\"\");\n",
    "\n",
    "dataframe = dataframe.drop(columns = columns_to_be_dropped);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "Checkout the `main.ipynb` since I just copy-pasting the whole thing from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after cleaning:  (30000, 75)\n",
      "['LIMIT_BAL', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', 'BILL_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'LABEL', 'pay_0_-2', 'pay_0_-1', 'pay_0_0', 'pay_0_1', 'pay_0_2', 'pay_0_3', 'pay_0_4', 'pay_0_5', 'pay_0_6', 'pay_0_7', 'pay_0_8', 'pay_2_-2', 'pay_2_-1', 'pay_2_0', 'pay_2_1', 'pay_2_2', 'pay_2_3', 'pay_2_4', 'pay_2_5', 'pay_2_6', 'pay_2_7', 'pay_2_8', 'pay_3_-2', 'pay_3_-1', 'pay_3_0', 'pay_3_1', 'pay_3_2', 'pay_3_3', 'pay_3_4', 'pay_3_5', 'pay_3_6', 'pay_3_7', 'pay_3_8', 'pay_4_-2', 'pay_4_-1', 'pay_4_0', 'pay_4_1', 'pay_4_2', 'pay_4_3', 'pay_4_4', 'pay_4_5', 'pay_4_6', 'pay_4_7', 'pay_4_8', 'pay_5_-2', 'pay_5_-1', 'pay_5_0', 'pay_5_2', 'pay_5_3', 'pay_5_4', 'pay_5_5', 'pay_5_6', 'pay_5_7', 'pay_5_8', 'pay_6_-2', 'pay_6_-1', 'pay_6_0', 'pay_6_2', 'pay_6_3', 'pay_6_4', 'pay_6_5', 'pay_6_6', 'pay_6_7', 'pay_6_8']\n"
     ]
    }
   ],
   "source": [
    "# Make one hot encoding for PAY_0 to 6 since the data is an ordinal data\n",
    "hot_encoded_pay_0 = pandas.get_dummies(dataframe['PAY_0'], prefix = \"pay_0\");\n",
    "hot_encoded_pay_2 = pandas.get_dummies(dataframe['PAY_2'], prefix = \"pay_2\");\n",
    "hot_encoded_pay_3 = pandas.get_dummies(dataframe['PAY_3'], prefix = \"pay_3\");\n",
    "hot_encoded_pay_4 = pandas.get_dummies(dataframe['PAY_4'], prefix = \"pay_4\");\n",
    "hot_encoded_pay_5 = pandas.get_dummies(dataframe['PAY_5'], prefix = \"pay_5\");\n",
    "hot_encoded_pay_6 = pandas.get_dummies(dataframe['PAY_6'], prefix = \"pay_6\");\n",
    "\n",
    "# Merge the hot_encoded with the main dataframe\n",
    "for i in [hot_encoded_pay_0, hot_encoded_pay_2, hot_encoded_pay_3, hot_encoded_pay_4, hot_encoded_pay_5, hot_encoded_pay_6]:\n",
    "    dataframe = pandas.concat([dataframe, i], axis = 1);\n",
    "\n",
    "print(\"Data after cleaning: \", dataframe.shape);\n",
    "print(dataframe.columns.tolist());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape:  (30000, 68)\n"
     ]
    }
   ],
   "source": [
    "# Define label data\n",
    "label = dataframe['LABEL'];\n",
    "\n",
    "# Drop ID, SEX, EDUCATION, MARRIAGE, and LABEL from dataframe for features\n",
    "features = dataframe.drop(columns=['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6', \"LABEL\"]);\n",
    "\n",
    "# Typecasting all values within to int64 because ANN need to be standardized\n",
    "\n",
    "for i in dataframe.columns:\n",
    "    dataframe[i] = dataframe[i].astype(int);\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "feature_train, feature_test, label_train, label_test = train_test_split(features, label, train_size = 0.7, test_size = 0.3, random_state = 42);\n",
    "feature_validation, feature_test, label_validation, label_test = train_test_split(feature_test, label_test, test_size=0.5, random_state = 42);\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler();\n",
    "feature_train_scaled = scaler.fit_transform(feature_train);\n",
    "feature_validation_scaled = scaler.fit_transform(feature_validation);\n",
    "feature_test_scaled = scaler.transform(feature_test);\n",
    "\n",
    "print(\"Features shape: \", features.shape);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def telegram_reporter(message):\n",
    "    message = \"[\"+ time.strftime(\"%Y-%m-%d %H:%M:%S\") +\"] \" + message\n",
    "    requests.request(method=\"POST\", url=\"https://api.telegram.org/bot:telegram_bot_token/sendMessage?chat_id=:your_chat_id&text=\" + message, headers={}, data={});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tunning\n",
    "\n",
    "This code based on Tensorflow Artifical Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.src.backend' has no attribute 'RandomGenerator'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Code\\College\\Machine Learning\\Team Assignment\\Default Credit Scoring\\cua\\dojo-ann.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m model;\n\u001b[1;32m    <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m dojo \u001b[39m=\u001b[39m ANNModel();\n\u001b[0;32m--> <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m model \u001b[39m=\u001b[39m dojo\u001b[39m.\u001b[39;49mfit();\n\u001b[1;32m    <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(feature_test_scaled, label_test);\n\u001b[1;32m    <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLoss: \u001b[39m\u001b[39m\"\u001b[39m, loss, \u001b[39m\"\u001b[39m\u001b[39m Accuracy: \u001b[39m\u001b[39m\"\u001b[39m, accuracy);\n",
      "\u001b[1;32md:\\Code\\College\\Machine Learning\\Team Assignment\\Default Credit Scoring\\cua\\dojo-ann.ipynb Cell 12\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m model \u001b[39m=\u001b[39m Sequential();\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m model\u001b[39m.\u001b[39madd(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_layer());\n\u001b[0;32m---> <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhidden_layer(), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshallow_hidden_layer()]:\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=84'>85</a>\u001b[0m     \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m i:\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=85'>86</a>\u001b[0m         model\u001b[39m.\u001b[39madd(j);\n",
      "\u001b[1;32md:\\Code\\College\\Machine Learning\\Team Assignment\\Default Credit Scoring\\cua\\dojo-ann.ipynb Cell 12\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhidden_layer\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m----> <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         keras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mDense(\u001b[39m256\u001b[39;49m, kernel_initializer \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mglorot_uniform\u001b[39;49m\u001b[39m\"\u001b[39;49m, kernel_regularizer \u001b[39m=\u001b[39;49m tensorflow\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mregularizers\u001b[39m.\u001b[39;49ml2(\u001b[39m1e-4\u001b[39;49m)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mActivation(\u001b[39m\"\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mBatchNormalization(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDropout(\u001b[39m0.5\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m256\u001b[39m, kernel_initializer \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mglorot_uniform\u001b[39m\u001b[39m\"\u001b[39m, kernel_regularizer \u001b[39m=\u001b[39m tensorflow\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mregularizers\u001b[39m.\u001b[39ml2(\u001b[39m1e-4\u001b[39m)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mActivation(\u001b[39m\"\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mBatchNormalization(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDropout(\u001b[39m0.5\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         \n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m128\u001b[39m, kernel_initializer \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mglorot_uniform\u001b[39m\u001b[39m\"\u001b[39m, kernel_regularizer \u001b[39m=\u001b[39m tensorflow\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mregularizers\u001b[39m.\u001b[39ml2(\u001b[39m1e-4\u001b[39m)),\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mBatchNormalization(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDropout(\u001b[39m0.5\u001b[39m),\n\u001b[1;32m     <a href='vscode-notebook-cell:/d%3A/Code/College/Machine%20Learning/Team%20Assignment/Default%20Credit%20Scoring/cua/dojo-ann.ipynb#X14sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_team/lib/python3.10/site-packages/keras/src/dtensor/utils.py:96\u001b[0m, in \u001b[0;36mallow_initializer_layout.<locals>._wrap_function\u001b[0;34m(layer_instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[39mif\u001b[39;00m layout:\n\u001b[1;32m     94\u001b[0m             layout_args[variable_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_layout\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m layout\n\u001b[0;32m---> 96\u001b[0m init_method(layer_instance, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     98\u001b[0m \u001b[39m# Inject the layout parameter after the invocation of __init__()\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[39mfor\u001b[39;00m layout_param_name, layout \u001b[39min\u001b[39;00m layout_args\u001b[39m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_team/lib/python3.10/site-packages/keras/src/layers/core/dense.py:127\u001b[0m, in \u001b[0;36mDense.__init__\u001b[0;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation \u001b[39m=\u001b[39m activations\u001b[39m.\u001b[39mget(activation)\n\u001b[1;32m    126\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias \u001b[39m=\u001b[39m use_bias\n\u001b[0;32m--> 127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_initializer \u001b[39m=\u001b[39m initializers\u001b[39m.\u001b[39;49mget(kernel_initializer)\n\u001b[1;32m    128\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias_initializer \u001b[39m=\u001b[39m initializers\u001b[39m.\u001b[39mget(bias_initializer)\n\u001b[1;32m    129\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_regularizer \u001b[39m=\u001b[39m regularizers\u001b[39m.\u001b[39mget(kernel_regularizer)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_team/lib/python3.10/site-packages/keras/src/initializers/__init__.py:217\u001b[0m, in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(identifier, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    216\u001b[0m     config \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mclass_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mstr\u001b[39m(identifier), \u001b[39m\"\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m\"\u001b[39m: {}}\n\u001b[0;32m--> 217\u001b[0m     \u001b[39mreturn\u001b[39;00m get(config)\n\u001b[1;32m    218\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mcallable\u001b[39m(identifier):\n\u001b[1;32m    219\u001b[0m     \u001b[39mif\u001b[39;00m inspect\u001b[39m.\u001b[39misclass(identifier):\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_team/lib/python3.10/site-packages/keras/src/initializers/__init__.py:214\u001b[0m, in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(identifier, \u001b[39mdict\u001b[39m):\n\u001b[1;32m    213\u001b[0m     use_legacy_format \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmodule\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m identifier\n\u001b[0;32m--> 214\u001b[0m     \u001b[39mreturn\u001b[39;00m deserialize(identifier, use_legacy_format\u001b[39m=\u001b[39;49muse_legacy_format)\n\u001b[1;32m    215\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(identifier, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    216\u001b[0m     config \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mclass_name\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mstr\u001b[39m(identifier), \u001b[39m\"\u001b[39m\u001b[39mconfig\u001b[39m\u001b[39m\"\u001b[39m: {}}\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_team/lib/python3.10/site-packages/keras/src/initializers/__init__.py:161\u001b[0m, in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects, use_legacy_format)\u001b[0m\n\u001b[1;32m    159\u001b[0m populate_deserializable_objects()\n\u001b[1;32m    160\u001b[0m \u001b[39mif\u001b[39;00m use_legacy_format:\n\u001b[0;32m--> 161\u001b[0m     \u001b[39mreturn\u001b[39;00m legacy_serialization\u001b[39m.\u001b[39;49mdeserialize_keras_object(\n\u001b[1;32m    162\u001b[0m         config,\n\u001b[1;32m    163\u001b[0m         module_objects\u001b[39m=\u001b[39;49mLOCAL\u001b[39m.\u001b[39;49mALL_OBJECTS,\n\u001b[1;32m    164\u001b[0m         custom_objects\u001b[39m=\u001b[39;49mcustom_objects,\n\u001b[1;32m    165\u001b[0m         printable_module_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39minitializer\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    166\u001b[0m     )\n\u001b[1;32m    168\u001b[0m \u001b[39mreturn\u001b[39;00m serialization_lib\u001b[39m.\u001b[39mdeserialize_keras_object(\n\u001b[1;32m    169\u001b[0m     config,\n\u001b[1;32m    170\u001b[0m     module_objects\u001b[39m=\u001b[39mLOCAL\u001b[39m.\u001b[39mALL_OBJECTS,\n\u001b[1;32m    171\u001b[0m     custom_objects\u001b[39m=\u001b[39mcustom_objects,\n\u001b[1;32m    172\u001b[0m     printable_module_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minitializer\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    173\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_team/lib/python3.10/site-packages/keras/src/saving/legacy/serialization.py:507\u001b[0m, in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m         \u001b[39mwith\u001b[39;00m object_registration\u001b[39m.\u001b[39mCustomObjectScope(custom_objects):\n\u001b[0;32m--> 507\u001b[0m             deserialized_obj \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49mfrom_config(cls_config)\n\u001b[1;32m    508\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    509\u001b[0m     \u001b[39m# Then `cls` may be a function returning a class.\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[39m# in this case by convention `config` holds\u001b[39;00m\n\u001b[1;32m    511\u001b[0m     \u001b[39m# the kwargs of the function.\u001b[39;00m\n\u001b[1;32m    512\u001b[0m     custom_objects \u001b[39m=\u001b[39m custom_objects \u001b[39mor\u001b[39;00m {}\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_team/lib/python3.10/site-packages/keras/src/initializers/initializers.py:115\u001b[0m, in \u001b[0;36mInitializer.from_config\u001b[0;34m(cls, config)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Instantiates an initializer from a configuration dictionary.\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \n\u001b[1;32m    100\u001b[0m \u001b[39mExample:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[39m    An `Initializer` instance.\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    114\u001b[0m config\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m--> 115\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mconfig)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_team/lib/python3.10/site-packages/keras/src/initializers/initializers.py:884\u001b[0m, in \u001b[0;36mGlorotUniform.__init__\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, seed\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 884\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    885\u001b[0m         scale\u001b[39m=\u001b[39;49m\u001b[39m1.0\u001b[39;49m, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mfan_avg\u001b[39;49m\u001b[39m\"\u001b[39;49m, distribution\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39muniform\u001b[39;49m\u001b[39m\"\u001b[39;49m, seed\u001b[39m=\u001b[39;49mseed\n\u001b[1;32m    886\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ml_team/lib/python3.10/site-packages/keras/src/initializers/initializers.py:612\u001b[0m, in \u001b[0;36mVarianceScaling.__init__\u001b[0;34m(self, scale, mode, distribution, seed)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdistribution \u001b[39m=\u001b[39m distribution\n\u001b[1;32m    611\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseed \u001b[39m=\u001b[39m seed\n\u001b[0;32m--> 612\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_random_generator \u001b[39m=\u001b[39m backend\u001b[39m.\u001b[39;49mRandomGenerator(\n\u001b[1;32m    613\u001b[0m     seed, rng_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstateless\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    614\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.src.backend' has no attribute 'RandomGenerator'"
     ]
    }
   ],
   "source": [
    "class ANNModel:\n",
    "\n",
    "    # Hyperparameters\n",
    "    def input_layer(self):\n",
    "        return keras.layers.InputLayer(input_shape = (68,)); # 11 is total features dimension\n",
    "\n",
    "    def hidden_layer(self):\n",
    "        return [\n",
    "            keras.layers.Dense(512, kernel_initializer = \"glorot_uniform\", kernel_regularizer = tensorflow.keras.regularizers.l2(1e-4), activity_regularizer = tensorflow.keras.regularizers.l2(1e-4)),\n",
    "            keras.layers.Activation(\"sigmoid\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dropout(0.8),\n",
    "\n",
    "            keras.layers.Dense(256, kernel_initializer = \"glorot_uniform\", kernel_regularizer = tensorflow.keras.regularizers.l2(1e-4), activity_regularizer = tensorflow.keras.regularizers.l2(1e-4)),\n",
    "            keras.layers.Activation(\"sigmoid\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dropout(0.5),\n",
    "\n",
    "            keras.layers.Dense(256, kernel_initializer = \"glorot_uniform\", kernel_regularizer = tensorflow.keras.regularizers.l2(1e-4), activity_regularizer = tensorflow.keras.regularizers.l2(1e-4)),\n",
    "            keras.layers.Activation(\"sigmoid\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dropout(0.5),\n",
    "\n",
    "            keras.layers.Dense(128, kernel_initializer = \"glorot_uniform\", kernel_regularizer = tensorflow.keras.regularizers.l2(1e-4), activity_regularizer = tensorflow.keras.regularizers.l2(1e-4)),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dropout(0.5),\n",
    "        ];\n",
    "\n",
    "    def shallow_hidden_layer(self):\n",
    "        return [\n",
    "            keras.layers.Dense(64, kernel_initializer = \"glorot_uniform\", kernel_regularizer = tensorflow.keras.regularizers.l2(1e-4)),\n",
    "            keras.layers.Activation(\"sigmoid\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dropout(0.5),\n",
    "\n",
    "            keras.layers.Dense(64, kernel_initializer = \"glorot_uniform\", kernel_regularizer = tensorflow.keras.regularizers.l2(1e-4)),\n",
    "            keras.layers.Activation(\"sigmoid\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dropout(0.5),\n",
    "\n",
    "            keras.layers.Dense(32, kernel_initializer = \"glorot_uniform\", kernel_regularizer = tensorflow.keras.regularizers.l2(1e-3)),\n",
    "            keras.layers.Activation(\"sigmoid\"),\n",
    "            keras.layers.BatchNormalization(),\n",
    "            keras.layers.Dropout(0.5),\n",
    "        ];\n",
    "\n",
    "    def output_layer(self):\n",
    "        return keras.layers.Dense(1, kernel_initializer = \"glorot_uniform\", activation = \"sigmoid\"); # Since output is only 1 label.\n",
    "\n",
    "    def optimizer(self):\n",
    "        return keras.optimizers.Adam(learning_rate = 1e-3);\n",
    "\n",
    "    def loss(self):\n",
    "        return \"binary_crossentropy\";\n",
    "\n",
    "    def metrics(self):\n",
    "        return \"accuracy\";\n",
    "\n",
    "    def epoch(self):\n",
    "        return 1000;\n",
    "\n",
    "        \n",
    "    # Callbacks\n",
    "    # Backup Model to h5 file\n",
    "    def _callback_model_backup(self):\n",
    "        checkpoint_path = current_folder + \"/cua/\" + \"model_checkpoint.h5\";\n",
    "\n",
    "        return tensorflow.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_path,\n",
    "            save_weights_only=True,\n",
    "            save_freq='epoch'\n",
    "        );\n",
    "\n",
    "    # Early stopping after loss are not improved for some epochs\n",
    "    def _callback_early_stopping(self):\n",
    "        early_stopping_tolerance = 50;\n",
    "\n",
    "        return tensorflow.keras.callbacks.EarlyStopping(\n",
    "            monitor = \"val_loss\",\n",
    "            patience = early_stopping_tolerance,\n",
    "            restore_best_weights = True\n",
    "        );\n",
    "\n",
    "    # Fitting\n",
    "    def fit(self):\n",
    "\n",
    "        # Construct the model \n",
    "        model = Sequential();\n",
    "        model.add(self.input_layer());\n",
    "\n",
    "        for i in [self.hidden_layer(), self.shallow_hidden_layer()]:\n",
    "            for j in i:\n",
    "                model.add(j);\n",
    "                print(model.output_shape)\n",
    "\n",
    "        model.add(self.output_layer());\n",
    "\n",
    "        # Draw the model architecture\n",
    "        plot_model(model, to_file=(current_folder + \"/cua/\" + \"model_architecture.png\"), show_shapes=True)\n",
    "        model.summary()\n",
    "\n",
    "        # Compile the model pipeline\n",
    "        model.compile(loss = self.loss(), optimizer = self.optimizer(), metrics=[self.metrics()]);\n",
    "\n",
    "        telegram_reporter(\"Starting training model with code [202401200128] with total epoch of \" + str(self.epoch()));\n",
    "\n",
    "        # Fitting\n",
    "        model_plot = model.fit(\n",
    "            feature_train_scaled, \n",
    "            label_train, \n",
    "            epochs = self.epoch(), \n",
    "            validation_data = (feature_validation_scaled, label_validation), \n",
    "            callbacks = [self._callback_model_backup(), self._callback_early_stopping()] \n",
    "        );\n",
    "\n",
    "        plt.plot(model_plot.history[\"loss\"], label = \"Model Training Loss\");\n",
    "        plt.plot(model_plot.history[\"val_loss\"], label = \"Model Validation Loss\");\n",
    "        plt.title(\"Training and Validation Loss\");\n",
    "        plt.xlabel(\"Epochs\");\n",
    "        plt.ylabel(\"Loss\");\n",
    "        plt.legend();\n",
    "        plt.show();\n",
    "\n",
    "        return model;\n",
    "\n",
    "dojo = ANNModel();\n",
    "model = dojo.fit();\n",
    "\n",
    "loss, accuracy = model.evaluate(feature_test_scaled, label_test);\n",
    "print(\"Loss: \", loss, \" Accuracy: \", accuracy);\n",
    "\n",
    "telegram_reporter(\"Finished training with Loss: \" + str(loss) + \" Accuracy: \" + str(accuracy));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
